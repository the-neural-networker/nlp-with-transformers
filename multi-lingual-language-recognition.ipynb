{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (/u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.te/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f311afdc8b348af88eb24ecc7249265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"xtreme\", name=\"PAN-X.te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (/u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca44de32b854a6d9f1fc5e98733d01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-68314036533271e4.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-8dbe0c17aec505e3.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-16c4e170f4c083d6.arrow\n",
      "Found cached dataset xtreme (/u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.te/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ca47e6655645daaff51fdebf81de3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.te/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-021189a66c8ca2fc.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.te/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-a6dd7522f39237eb.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.te/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-fb8462d1a7a7ec54.arrow\n",
      "Found cached dataset xtreme (/u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.ta/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5d9d7e0e0b4ae78d432d2ccca4c10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.ta/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-6ce4719467e98050.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.ta/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-ba0404565ea374a4.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.ta/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-29467d2078f2faf4.arrow\n",
      "Found cached dataset xtreme (/u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a73ea2d7cac4790951a0792bfa57389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e14b50505509ca06.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-529925d4984531e4.arrow\n",
      "Loading cached shuffled indices for dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-ef60137063549caf.arrow\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict \n",
    "\n",
    "langs = [\"hi\", \"te\", \"ta\", \"en\"]\n",
    "fracs = [0.5709, 0.0777, 0.6360, 0.1067]\n",
    "fracs = [frac / sum(fracs) for frac in fracs]\n",
    "# return a DatasetDict if a key does not exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # load multilingual corpus \n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=42)\n",
    "            .select(range(int(frac * ds[split].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hi</th>\n",
       "      <th>te</th>\n",
       "      <th>ta</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>2051</td>\n",
       "      <td>55</td>\n",
       "      <td>6856</td>\n",
       "      <td>1533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               hi  te    ta    en\n",
       "Number of training examples  2051  55  6856  1533"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, \n",
    "             index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['प्रेम', 'चोपड़ा', '-', 'गिरिधारीलाल']\n",
      "ner_tags: [1, 2, 0, 0]\n",
      "langs: ['hi', 'hi', 'hi', 'hi']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"hi\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"hi\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"hi\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-a5e82638fe2cec57.arrow\n",
      "Loading cached processed dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-a4af9bc9df139198.arrow\n",
      "Loading cached processed dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-8fa5e26de647100a.arrow\n"
     ]
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "\n",
    "panx_hi = panx_ch[\"hi\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>प्रेम</td>\n",
       "      <td>चोपड़ा</td>\n",
       "      <td>-</td>\n",
       "      <td>गिरिधारीलाल</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1  2            3\n",
       "Tokens  प्रेम  चोपड़ा  -  गिरिधारीलाल\n",
       "Tags    B-PER   I-PER  O            O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi_example = panx_hi[\"train\"][0]\n",
    "pd.DataFrame([hi_example[\"tokens\"], hi_example[\"ner_tags_str\"]], ['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PER</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>945</td>\n",
       "      <td>753</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>158</td>\n",
       "      <td>151</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PER  ORG  LOC\n",
       "train       945  753  790\n",
       "validation  177  140  185\n",
       "test        158  151  176"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_hi.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1 \n",
    "\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilingual transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whitespace is preserved by using xlmr which uses the SentencePiece tokenizer\n",
    "\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers for Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(XLMRobertaForTokenClassification, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # set up token classification head \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # load and initialize weights \n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        # use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
    "        # apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # calculate losses \n",
    "        loss = None \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # return model output object \n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, num_labels=tags.num_classes, id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on a small sequence of known entities \n",
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits \n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(F\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4  5     6      7  8     9\n",
       "Tokens  <s>  ▁Jack  ▁Spar  row  ▁love  s  ▁New  ▁York  !  </s>\n",
       "Tags      O      O      O    O      O  O     O      O  O     O"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # get predictions as a distribution over 7 possible classes \n",
    "    outputs = model(input_ids)[0]\n",
    "    # take argmax to get most likely class per token \n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # convert to dataframe\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Texts for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = hi_example[\"tokens\"], hi_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁प्रेम</td>\n",
       "      <td>▁चोपड़ा</td>\n",
       "      <td>▁-</td>\n",
       "      <td>▁गिरि</td>\n",
       "      <td>धारी</td>\n",
       "      <td>लाल</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1        2   3      4     5    6     7\n",
       "Tokens  <s>  ▁प्रेम  ▁चोपड़ा  ▁-  ▁गिरि  धारी  लाल  </s>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(hi_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁प्रेम</td>\n",
       "      <td>▁चोपड़ा</td>\n",
       "      <td>▁-</td>\n",
       "      <td>▁गिरि</td>\n",
       "      <td>धारी</td>\n",
       "      <td>लाल</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1        2   3      4     5    6     7\n",
       "Tokens     <s>  ▁प्रेम  ▁चोपड़ा  ▁-  ▁गिरि  धारी  लाल  </s>\n",
       "Word IDs  None       0        1   2      3     3    3  None"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to mask the subwords after the first subword\n",
    "word_ids = tokenized_input.word_ids() \n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁प्रेम</td>\n",
       "      <td>▁चोपड़ा</td>\n",
       "      <td>▁-</td>\n",
       "      <td>▁गिरि</td>\n",
       "      <td>धारी</td>\n",
       "      <td>लाल</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1        2   3      4     5     6     7\n",
       "Tokens       <s>  ▁प्रेम  ▁चोपड़ा  ▁-  ▁गिरि  धारी   लाल  </s>\n",
       "Word IDs    None       0        1   2      3     3     3  None\n",
       "Label IDs   -100       1        2   0      0  -100  -100  -100\n",
       "Labels     B-PER   I-PER        O   O   None  None  None  None"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None \n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in labels]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = [] \n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None \n",
    "        label_ids = [] \n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2051 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-aab488dfd93052f0.arrow\n",
      "Loading cached processed dataset at /u/akommala/.cache/huggingface/datasets/xtreme/PAN-X.hi/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-1326b99fc5dcd9d0.arrow\n"
     ]
    }
   ],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, remove_columns=['langs', 'ner_tags', 'tokens'])\n",
    "\n",
    "panx_hi_encoded = encode_panx_dataset(panx_ch[\"hi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"], [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"], [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], [] \n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], [] \n",
    "        for seq_idx in range(seq_len):\n",
    "            # ignore label ids = -100 \n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_hi_encoded[\"train\"]) // batch_size \n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-hi\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926c52210e5645988d3d7abe286d16f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login \n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification \n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/akommala/xlm-roberta-base-finetuned-panx-hi into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer \n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args, data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                   train_dataset=panx_hi_encoded[\"train\"], eval_dataset=panx_hi_encoded[\"validation\"], tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/akommala/nlp-with-transformers/env/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/u/akommala/nlp-with-transformers/env/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.430049</td>\n",
       "      <td>0.656420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.716200</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.802337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.716200</td>\n",
       "      <td>0.279025</td>\n",
       "      <td>0.829746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f956ab501f164a7b8b5157a64eefb1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf6f2e7bef3408488a753f71baa6fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tokenizer.json:   0%|          | 1.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05dbc4cff69441e95ebf19601bd5e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/3.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/akommala/xlm-roberta-base-finetuned-panx-hi\n",
      "   1e1c5d9..6476c27  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/akommala/xlm-roberta-base-finetuned-panx-hi\n",
      "   6476c27..b74918b  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/akommala/xlm-roberta-base-finetuned-panx-hi/commit/6476c27493aad6ba27bb1a4c7dfbebf307d60757'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁तेजी</td>\n",
       "      <td>▁बच्चन</td>\n",
       "      <td>▁से</td>\n",
       "      <td>▁अमिताभ</td>\n",
       "      <td>▁तथा</td>\n",
       "      <td>▁अज</td>\n",
       "      <td>िता</td>\n",
       "      <td>भ</td>\n",
       "      <td>▁दो</td>\n",
       "      <td>▁पुत्र</td>\n",
       "      <td>▁हुए</td>\n",
       "      <td>▁।</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2    3        4     5      6      7      8    9    \n",
       "Tokens  <s>  ▁तेजी  ▁बच्चन  ▁से  ▁अमिताभ  ▁तथा    ▁अज    िता      भ  ▁दो  \\\n",
       "Tags      O  B-PER   I-PER    O    B-PER     O  B-PER  I-PER  I-PER    O   \n",
       "\n",
       "            10    11  12    13  \n",
       "Tokens  ▁पुत्र  ▁हुए  ▁।  </s>  \n",
       "Tags         O     O   O     O  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_hi = \"तेजी बच्चन से अमिताभ तथा अजिताभ दो पुत्र हुए ।\"\n",
    "tag_text(text_hi, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # convert dict of lists of list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size [batch_size, sequence_length, classes]\n",
    "        # predict class with largest logit value on classes axis \n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy() \n",
    "    \n",
    "    # calculate loss per token after flattening batch dimension with view \n",
    "    loss = cross_entropy(output.logits.view(-1, 7), labels.view(-1), reduction=\"none\") \n",
    "    # unflatten batch dimension and convert to numpy array \n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy() \n",
    "    \n",
    "    return {'loss': loss, 'predicted_label': predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_hi_encoded[\"validation\"] \n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 2218, 14136, 5988, 67691, 460, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.03533609, 0.0, 0.027601829, 0.02570483...</td>\n",
       "      <td>[O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]</td>\n",
       "      <td>[&lt;s&gt;, ▁स, जन, ▁घर, ▁जाना, ▁है, &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 93019, 7475, 976, 156711, 41612, 3558, 967...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, IGN, IGN, IGN, B-PER, IGN, IGN, IGN, ...</td>\n",
       "      <td>[0.0, 0.0056619984, 0.0, 0.0, 0.0, 0.019219365...</td>\n",
       "      <td>[O, O, O, O, O, B-PER, I-PER, I-PER, I-PER, I-...</td>\n",
       "      <td>[&lt;s&gt;, ▁पुनर्, प्र, े, षित, ▁फ़, ि, रो, ज़, ▁शा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 11026, 3849, 8389, 1471, 871, 76302, 659, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-LOC, IGN, IGN, IGN, I-LOC, I-LOC, IGN,...</td>\n",
       "      <td>[0.0, 0.07252373, 0.0, 0.0, 0.0, 0.05340195, 0...</td>\n",
       "      <td>[I-LOC, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-L...</td>\n",
       "      <td>[&lt;s&gt;, ▁ला, ह, ौ, ल, ▁और, ▁स्प, ी, ति, ▁जिला, &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 20571, 3282, 6, 150685, 20, 3813, 1187, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-PER, IGN, I-PER, IGN, O, O, IGN, IGN, ...</td>\n",
       "      <td>[0.0, 0.012027361, 0.0, 0.016277391, 0.0, 0.00...</td>\n",
       "      <td>[O, B-PER, I-PER, I-PER, I-PER, O, O, O, O, O]</td>\n",
       "      <td>[&lt;s&gt;, ▁अस, ित, ▁, सेन, ▁-, ▁था, ने, दार, &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 9163, 2629, 76183, 1472, 6, 4, 46005, 1187...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-LOC, IGN, IGN, IGN, I-LOC, IGN, I-LOC,...</td>\n",
       "      <td>[0.0, 0.055613037, 0.0, 0.0, 0.0, 1.1047724, 0...</td>\n",
       "      <td>[I-LOC, B-LOC, B-LOC, I-LOC, I-LOC, O, O, B-LO...</td>\n",
       "      <td>[&lt;s&gt;, ▁मे, म्, फि, स, ▁, ,, ▁टे, ने, सी, &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids   \n",
       "0              [0, 2218, 14136, 5988, 67691, 460, 2]  \\\n",
       "1  [0, 93019, 7475, 976, 156711, 41612, 3558, 967...   \n",
       "2  [0, 11026, 3849, 8389, 1471, 871, 76302, 659, ...   \n",
       "3  [0, 20571, 3282, 6, 150685, 20, 3813, 1187, 11...   \n",
       "4  [0, 9163, 2629, 76183, 1472, 6, 4, 46005, 1187...   \n",
       "\n",
       "                                     attention_mask   \n",
       "0                             [1, 1, 1, 1, 1, 1, 1]  \\\n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "2                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "4                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                              labels   \n",
       "0        [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]  \\\n",
       "1  [IGN, O, IGN, IGN, IGN, B-PER, IGN, IGN, IGN, ...   \n",
       "2  [IGN, B-LOC, IGN, IGN, IGN, I-LOC, I-LOC, IGN,...   \n",
       "3  [IGN, B-PER, IGN, I-PER, IGN, O, O, IGN, IGN, ...   \n",
       "4  [IGN, B-LOC, IGN, IGN, IGN, I-LOC, IGN, I-LOC,...   \n",
       "\n",
       "                                                loss   \n",
       "0  [0.0, 0.03533609, 0.0, 0.027601829, 0.02570483...  \\\n",
       "1  [0.0, 0.0056619984, 0.0, 0.0, 0.0, 0.019219365...   \n",
       "2  [0.0, 0.07252373, 0.0, 0.0, 0.0, 0.05340195, 0...   \n",
       "3  [0.0, 0.012027361, 0.0, 0.016277391, 0.0, 0.00...   \n",
       "4  [0.0, 0.055613037, 0.0, 0.0, 0.0, 1.1047724, 0...   \n",
       "\n",
       "                                     predicted_label   \n",
       "0          [O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O]  \\\n",
       "1  [O, O, O, O, O, B-PER, I-PER, I-PER, I-PER, I-...   \n",
       "2  [I-LOC, B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-L...   \n",
       "3     [O, B-PER, I-PER, I-PER, I-PER, O, O, O, O, O]   \n",
       "4  [I-LOC, B-LOC, B-LOC, I-LOC, I-LOC, O, O, B-LO...   \n",
       "\n",
       "                                        input_tokens  \n",
       "0               [<s>, ▁स, जन, ▁घर, ▁जाना, ▁है, </s>]  \n",
       "1  [<s>, ▁पुनर्, प्र, े, षित, ▁फ़, ि, रो, ज़, ▁शा...  \n",
       "2  [<s>, ▁ला, ह, ौ, ल, ▁और, ▁स्प, ी, ति, ▁जिला, <...  \n",
       "3     [<s>, ▁अस, ित, ▁, सेन, ▁-, ▁था, ने, दार, </s>]  \n",
       "4     [<s>, ▁मे, म्, फि, स, ▁, ,, ▁टे, ने, सी, </s>]  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x]) \n",
    "df[\"loss\"] = df.apply(\n",
    "    lambda x: x[\"loss\"][:len(x[\"input_ids\"])], axis=1)\n",
    "df[\"predicted_label\"] = df.apply(\n",
    "    lambda x: x[\"predicted_label\"][:len(x[\"input_ids\"])], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2218</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.04</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁स</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5988</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁घर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67691</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁जाना</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93019</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.01</td>\n",
       "      <td>O</td>\n",
       "      <td>▁पुनर्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41612</td>\n",
       "      <td>1</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>0.02</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>▁फ़</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51757</td>\n",
       "      <td>1</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>▁शाह</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label input_tokens\n",
       "0      2218              1  B-ORG  0.04           B-ORG           ▁स\n",
       "0      5988              1  I-ORG  0.03           I-ORG          ▁घर\n",
       "0     67691              1  I-ORG  0.03           I-ORG        ▁जाना\n",
       "0       460              1  I-ORG  0.03           I-ORG          ▁है\n",
       "1     93019              1      O  0.01               O       ▁पुनर्\n",
       "1     41612              1  B-PER  0.02           B-PER          ▁फ़\n",
       "1     51757              1  I-PER  0.03           I-PER         ▁शाह"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode) \n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2) \n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁का</td>\n",
       "      <td>▁सी</td>\n",
       "      <td>▁डी</td>\n",
       "      <td>▁क्रिकेट</td>\n",
       "      <td>▁राज्य</td>\n",
       "      <td>▁N</td>\n",
       "      <td>▁पाठ्यक्रम</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>235</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.07</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>74.51</td>\n",
       "      <td>33.85</td>\n",
       "      <td>32.66</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.21</td>\n",
       "      <td>7.71</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.07</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2      3     4     5         6       7     8   \n",
       "input_tokens      ▁     ▁)     ▁(    ▁का   ▁सी   ▁डी  ▁क्रिकेट  ▁राज्य    ▁N  \\\n",
       "count           235     80     80     39     7     6         4       9     1   \n",
       "mean           0.32   0.42   0.41   0.32   1.3  1.37      1.93    0.75  6.07   \n",
       "sum           74.51  33.85  32.66  12.56  9.11  8.21      7.71    6.71  6.07   \n",
       "\n",
       "                       9  \n",
       "input_tokens  ▁पाठ्यक्रम  \n",
       "count                  1  \n",
       "mean                5.71  \n",
       "sum                 5.71  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    " .agg([\"count\", \"mean\", \"sum\"])\n",
    " .droplevel(level=0, axis=1)\n",
    " .sort_values(by=\"sum\", ascending=False)\n",
    " .reset_index()\n",
    " .round(2)\n",
    " .head(10)\n",
    " .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>407</td>\n",
       "      <td>163</td>\n",
       "      <td>976</td>\n",
       "      <td>259</td>\n",
       "      <td>185</td>\n",
       "      <td>140</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>138.0</td>\n",
       "      <td>120.02</td>\n",
       "      <td>119.42</td>\n",
       "      <td>78.68</td>\n",
       "      <td>72.38</td>\n",
       "      <td>65.3</td>\n",
       "      <td>43.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2      3      4      5      6\n",
       "labels  I-ORG   I-LOC       O  I-PER  B-LOC  B-ORG  B-PER\n",
       "count     407     163     976    259    185    140    177\n",
       "mean     0.34    0.74    0.12    0.3   0.39   0.47   0.25\n",
       "sum     138.0  120.02  119.42  78.68  72.38   65.3  43.59"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIjCAYAAADP4ysCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACgx0lEQVR4nOzddVhUaRsG8HuGVkJBEAQkpMNGMMHEjrW7C9fuWLvXWHdVDOzuwlgDRfczwMDEFkVFQRpFcr4/BgYHBgQlZnbv33XNpZx5zpn3fXjPmWfec84gEIlEIhARERHJOWFJN4CIiIgoP1i0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBD9B3l4eMDDw0Pyc0hICAQCAbZu3Vqs7ejXrx/Mzc2L9TULIiEhAYMGDYKhoSEEAgHGjBlT6K9hbm6Ofv36Ffp2FZ28jw0qGSxaiGTYunUrBAIB1NXV8e7duxzPe3h4wMnJqQRaRsVp4cKF2Lp1K4YPH44dO3agd+/eJd0khfPlyxfMnj0bly5dKumm0L+Ackk3gEieJSUlYfHixfjrr79KuilFyszMDImJiVBRUSnppsgVPz8/uLm5YdasWUX2Gk+ePIFQ+O/9/PjlyxfMmTMHAKRm975n48aNSE9PL6JWkaL69+4pRIWgatWq2LhxI96/f19kryESiZCYmFhk28+PzFklJSWlEm2HvAkPD0eZMmWK9DXU1NRYLH7j8+fPAAAVFRWoqamVcGtI3rBoIcrDtGnTkJaWhsWLF383NjU1FfPmzUOlSpWgpqYGc3NzTJs2DUlJSVJx5ubmaN26Nf7++2/UrFkTGhoaWL9+PS5dugSBQID9+/djzpw5MDY2hpaWFjp16oTY2FgkJSVhzJgxMDAwgKamJvr3759j21u2bEGjRo1gYGAANTU1ODg4wNvb+7ttz35NS2ZbZD2yX2dw+vRp1K9fH6VLl4aWlhZatWqFhw8f5niNo0ePwsnJCerq6nBycsKRI0e+267sr+Pu7g4tLS1oa2vDxcUFu3fvloo5cOAAatSoAQ0NDZQrVw69evXKcXqvX79+0NTUxLt379C+fXtoampCX18fEyZMQFpamlT/X716hZMnT0r6HhISIjl1GBISIrXdzHW+PQ3y7NkzdOzYEYaGhlBXV4eJiQm6deuG2NhYSYysa1pevnyJzp07Q1dXF6VKlYKbmxtOnjwp8/X279+PBQsWwMTEBOrq6mjcuDGeP3/+3XzOnj0bAoEAT58+Ra9evaCjowN9fX389ttvEIlECA0NRbt27aCtrQ1DQ0MsX75cav3k5GTMnDkTNWrUgI6ODkqXLo369evj4sWLkpiQkBDo6+sDAObMmSPJ4+zZs6V+Fy9evEDLli2hpaWFnj17Sp77dqzNmjULQqEQFy5ckGrHkCFDoKqqirt37363z6T4eHqIKA8WFhbo06cPNm7ciClTpqBChQq5xg4aNAjbtm1Dp06dMH78eNy4cQOLFi1CcHBwjjfoJ0+eoHv37hg6dCgGDx4MW1tbyXOLFi2ChoYGpkyZgufPn+Ovv/6CiooKhEIhoqOjMXv2bFy/fh1bt26FhYUFZs6cKVnX29sbjo6OaNu2LZSVlXHixAl4eXkhPT0dI0aMyHe/7e3tsWPHDqllMTExGDduHAwMDCTLduzYgb59+8LT0xNLlizBly9f4O3tjXr16uHOnTuSN52zZ8+iY8eOcHBwwKJFixAZGYn+/fvDxMQkX+3ZunUrBgwYAEdHR0ydOhVlypTBnTt3cObMGfTo0UMS079/f7i4uGDRokX4+PEjVq1ahf/973+4c+eO1IxJWloaPD094erqimXLluH8+fNYvnw5KlWqhOHDh0v6P3bsWJiYmGD8+PEAIHkDzo/k5GR4enoiKSkJI0eOhKGhId69ewdfX1/ExMRAR0dH5nofP35EnTp18OXLF4waNQp6enrYtm0b2rZti4MHD6JDhw5S8YsXL4ZQKMSECRMQGxuLpUuXomfPnrhx40a+2tm1a1fY29tj8eLFOHnyJObPnw9dXV2sX78ejRo1wpIlS7Br1y5MmDABLi4uaNCgAQAgLi4OPj4+6N69OwYPHoz4+Hhs2rQJnp6eCAgIQNWqVaGvrw9vb28MHz4cHTp0wC+//AIAqFy5suT1U1NT4enpiXr16mHZsmUoVaqUzHbOmDEDJ06cwMCBA3H//n1oaWnh77//xsaNGzFv3jxUqVIlX/0lBSciohy2bNkiAiAKDAwUvXjxQqSsrCwaNWqU5Hl3d3eRo6Oj5OegoCARANGgQYOktjNhwgQRAJGfn59kmZmZmQiA6MyZM1KxFy9eFAEQOTk5iZKTkyXLu3fvLhIIBKIWLVpIxdeuXVtkZmYmtezLly85+uLp6SmytLSUWubu7i5yd3eX/Pzq1SsRANGWLVtk5iM9PV3UunVrkaampujhw4cikUgkio+PF5UpU0Y0ePBgqdgPHz6IdHR0pJZXrVpVZGRkJIqJiZEsO3v2rAhAjj5kFxMTI9LS0hK5urqKEhMTc7RLJBKJkpOTRQYGBiInJyepGF9fXxEA0cyZMyXL+vbtKwIgmjt3rtS2qlWrJqpRo4bUMjMzM1GrVq2klmWOjVevXkktz/z9Xbx4USQSiUR37twRARAdOHAgz/6ZmZmJ+vbtK/l5zJgxIgCiK1euSJbFx8eLLCwsRObm5qK0tDSp17O3txclJSVJYletWiUCILp//36erztr1iwRANGQIUMky1JTU0UmJiYigUAgWrx4sWR5dHS0SENDQ6qdqampUq+bGVe+fHnRgAEDJMsiIiJEAESzZs3K0YbM38WUKVNkPpd9bNy/f1+kqqoqGjRokCg6OlpkbGwsqlmzpiglJSXPvtK/B08PEX2HpaUlevfujQ0bNiAsLExmzKlTpwAA48aNk1qe+Qk9+9S+hYUFPD09ZW6rT58+Utc4uLq6QiQSYcCAAVJxrq6uCA0NRWpqqmSZhoaG5P+xsbH49OkT3N3d8fLlS6lTEgU1b948+Pr6YuvWrXBwcAAAnDt3DjExMejevTs+ffokeSgpKcHV1VVymiAsLAxBQUHo27ev1OxC06ZNJdvKy7lz5xAfH48pU6ZAXV1d6jmBQAAAuHnzJsLDw+Hl5SUV06pVK9jZ2eXIPwAMGzZM6uf69evj5cuX+czI92X29e+//8aXL1/yvd6pU6dQq1Yt1KtXT7JMU1MTQ4YMQUhICB49eiQV379/f6iqqkp+rl+/PgDkuy+DBg2S/F9JSQk1a9aESCTCwIEDJcvLlCkDW1tbqW0qKSlJXjc9PR1RUVFITU1FzZo1cfv27Xz3FwCGDx+erzgnJyfMmTMHPj4+8PT0xKdPn7Bt2zYoK/OkwX8FixaifJgxYwZSU1Nzvbbl9evXEAqFsLKyklpuaGiIMmXK4PXr11LLLSwscn2tihUrSv2c+eZnamqaY3l6erpUMfK///0PTZo0QenSpVGmTBno6+tj2rRpAPDDRcuZM2cwZ84cTJ06FR07dpQsf/bsGQCgUaNG0NfXl3qcPXsW4eHhACDpu7W1dY5tf3taLDcvXrwAgDxvMc98DVnbs7Ozy5F/dXX1HKd6ypYti+jo6O+2J78sLCwwbtw4+Pj4oFy5cvD09MSaNWu++3t4/fq1zH7Y29tLnv9W9vFStmxZAMh3X2SNN3V1dZQrVy7H8uzb3LZtGypXrgx1dXXo6elBX18fJ0+eLNBYU1ZWzvdpQgCYOHEiqlSpgoCAAMyaNStfhS/9e7A8JcoHS0tL9OrVCxs2bMCUKVNyjcv85P89386IZJfbHTy5LReJRADEb+6NGzeGnZ0dVqxYAVNTU6iqquLUqVNYuXLlD90++urVK/Ts2RNNmzbF/PnzpZ7L3N6OHTtgaGiYY115/vT7M3dJ5fY7zryI91vLly9Hv379cOzYMZw9exajRo3CokWLcP369QK9Uefle+PiR9bPzzZ37tyJfv36oX379pg4cSIMDAygpKSERYsWSQrN/FBTUyvQLd8vX76UFMz379/P93r07yC/RxUiOTNjxgzs3LkTS5YsyfGcmZkZ0tPT8ezZM8knYkB8UWVMTAzMzMyKvH0nTpxAUlISjh8/LvXp+du7OQoiMTERv/zyC8qUKYM9e/bkeGOpVKkSAMDAwABNmjTJdTuZfc98o/nWkydPvtuOzNd58OBBjpms7K/x5MkTNGrUKMdrFGb+M2cyYmJipJZnnwHJ5OzsDGdnZ8yYMQNXr15F3bp1sW7duhxFYCYzMzOZeXn8+LHkeXlw8OBBWFpa4vDhw1KFXPbvtMlvIZ8f6enp6NevH7S1tTFmzBgsXLgQnTp1klzgS/9+PD1ElE+VKlVCr169sH79enz48EHquZYtWwIA/vjjD6nlK1asACC+tqKoZX46/vbTcGxsLLZs2fJD2xs2bBiePn2KI0eOSN6ov+Xp6QltbW0sXLgQKSkpOZ6PiIgAABgZGaFq1arYtm2b1GmDc+fO5bg+Q5ZmzZpBS0sLixYtwtevX6Wey+xrzZo1YWBggHXr1kndBn769GkEBwcXav4zi6jLly9LlqWlpWHDhg1ScXFxcVLXGwHiAkYoFOa4Vf1bLVu2REBAAK5duyZZ9vnzZ2zYsAHm5uZyczpE1ni7ceOGVLsBSO4Gyl7k/YgVK1bg6tWr2LBhA+bNm4c6depg+PDh+PTp009vmxQDZ1qICmD69OnYsWMHnjx5AkdHR8nyKlWqoG/fvtiwYQNiYmLg7u6OgIAAbNu2De3bt0fDhg2LvG3NmjWDqqoq2rRpg6FDhyIhIQEbN26EgYFBrhcQ5+bkyZPYvn07OnbsiHv37uHevXuS5zQ1NdG+fXtoa2vD29sbvXv3RvXq1dGtWzfo6+vjzZs3OHnyJOrWrYvVq1cDEN/G3apVK9SrVw8DBgxAVFQU/vrrLzg6OiIhISHPtmhra2PlypUYNGgQXFxc0KNHD5QtWxZ3797Fly9fsG3bNqioqGDJkiXo378/3N3d0b17d8ktz+bm5hg7dmzBE5oLR0dHuLm5YerUqYiKioKuri727t2bo0Dx8/PDr7/+is6dO8PGxgapqanYsWMHlJSUpK4Nym7KlCnYs2cPWrRogVGjRkFXVxfbtm3Dq1evcOjQIbn59tzWrVvj8OHD6NChA1q1aoVXr15h3bp1cHBwkPqdamhowMHBAfv27YONjQ10dXXh5ORU4D+DERwcjN9++w39+vVDmzZtAIhvc69atSq8vLywf//+Qu0fyamSu3GJSH59e8tzdpm3aX57y7NIJBKlpKSI5syZI7KwsBCpqKiITE1NRVOnThV9/fpVKk7WbbQiUdYtrNlvkc2tLZm3rEZEREiWHT9+XFS5cmWRurq6yNzcXLRkyRLR5s2bc9yi+71bnjNfU9Yj+22oFy9eFHl6eop0dHRE6urqokqVKon69esnunnzplTcoUOHRPb29iI1NTWRg4OD6PDhwzJva83N8ePHRXXq1BFpaGiItLW1RbVq1RLt2bNHKmbfvn2iatWqidTU1ES6urqinj17it6+fSsV07dvX1Hp0qVzbD8zn9/K7Xf14sULUZMmTURqamqi8uXLi6ZNmyY6d+6c1C3PL1++FA0YMEBUqVIlkbq6ukhXV1fUsGFD0fnz53O8xre3Emduv1OnTqIyZcqI1NXVRbVq1RL5+vpKxeQ2Xr53+3r2/n47fkSi3POT/Tb/9PR00cKFC0VmZmYiNTU1UbVq1US+vr4yf6dXr14V1ahRQ6Sqqip1+3Nur5X5XOZ2UlNTRS4uLiITExOp2+ZFoqxbvPft25dnf+nfQSAS5fNqLSIiIqISJB/zjERERETfwaKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAr9crpClp6fj/fv30NLSKtSvryYiIvo3EolEiI+PR4UKFb775YksWgrZ+/fvc/w1XiIiIspbaGjod/+QKIuWQqalpQUAUPVcCoFK7n/J97/gmU/Pkm6CXFAScsYNANLS+T2WAKCm8uN/YZr+neITc/7trv+S+Ph4VLO3kLx/5oVFSyHLPCUkUNH4zxct2traJd0EucCiRYxFixiLFspB5b9dtGTKzyUVvBCXiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFwKKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFoFzSDaD8GeRpj5FtnGFQRgMPXkdh8uZruP3iU67xw1o6YkAzO5iU00RU3FccuxGCubtvIiklDQAwuXM1TOlcXWqdp+9i4Dr2UJH242dtPnQFa3f5ISIqDg5WxlgwriOqO5jlGn/c7w6WbjiF0A9RsDDRxwyvNmhSx1Hy/O8+p3Hs/G28C4+BqooSKtuaYurQVqjuaF4Mvflxmw5expqdfgiPioOjlTEWje+E6o655+HYhTtYvOEkQsOiYGmqj99GtEXTjDykpKZh0TpfnL/2CK/fRUJLUx3uLrb4zastDPV1iqtLP4TjQWzjfn/8tfMCwiPj4GRtjCUTO6NGHm0+ev42Fq47iTdhkbA01cfske3RrG5WHkQiERatP4ntR68iNiERrpUtsXxKV1SqaFAMvflxzIPYtsP/YMNeP0RExcO+UgXMGf0LquaxX5y8GITlm07j7YcomBvrY8qw1mhU20HyvFmDsTLXmzq8DYZ1b1To7c8LZ1oUQIfaFpjfxxVLDt6Bx+RjePA6CoemN0c5bXWZ8Z3qWmJWj5pYeuAOXMcewsh1/6BDbQv81r2mVFzwm2jYDt4tebSY6Vsc3flhR8/fxuw/j2D8AE+c3TIRjlYV0H2sNyKi4mXGB95/heGztqN7Gzec2zoRLRo4o/+UTQh+8V4SU6miPhaO74RLOybjmPdomBrpousYb3yKTiiubhXYkXO3MXPVEUwY1BwXtk2Eo7UxuoxZm2seAu69xNCZ29CzTW34bZuEFg0qo+8kH0keEr8m496TtxjX3xMXtk3E1sUD8fx1OHpN3FCc3Sowjgexw2dvYcYfRzB5UAtc2jEZTtbG6DhyTa55uHH3JQbN2Ipe7WrDf+cUtHKvgl4TNuDR86w8rNp+Huv3+WPF1G44t2UCSmmoouPINfialFJc3Sow5kHsxIU7mL/mKEb384Svz3jYW1VA7wnr8Sladh5u3n+FkXN3oEsrV5z0mYBm9Z0wZPpmPHkZJokJPDJH6vH7lG4QCARo6V65uLolwaIlm9DQUAwYMAAVKlSAqqoqzMzMMHr0aERGRpZYm7xaO2H7hSfYfekZnryLwbiN/8OX5FT0amgjM76WbXnceBKOg/97idCIBFy89w6H/vcSNazKScWlpqcjPDZR8oiKTyqO7vyw9XsvoWfbOuje2g22FoZYOqkLNNRUsdf3usz4jfv90dDVDiN6NoaNuSEmD2kFZ1sTbDl0RRLzS7OaaOBiCzPjcrCzNMKcUR0Q//krgl+8K65uFdi6PRfRq10d9GjtBlsLIyyb3AUa6qrYnUseNuzzRyM3e/zaqzFsLAwxdWgrVLY1waaD4jxoa2rg4F8j0L5JdViZlUdNJwssntAJdx+H4u2HqOLsWoFwPIit3e2HPu3roGfb2rCzNMKKqd1QSl0VO49fkxm/fu8lNK5tj1G9m8DWwhDTh7dGFTtTbDzgD0A8u7Buz0VMGOCJlu6V4WRtDO85ffDhUyxO+t8tzq4VCPMg5rP/Erq1ro0uLV1hY26IheM7Q0NdFftP3pAZv+XgZbjXssOw7o1gbV4eEwa1hJONCbYdztovDPS0pR7n/nmA2tWsULFCOZnbLEosWr7x8uVL1KxZE8+ePcOePXvw/PlzrFu3DhcuXEDt2rURFVX8B3AVJSGqWpbDpftZ1b9IBPjffw8XG9lTlAFPPqKqpR6qVxIPKDMDLTStZopzd95KxVkaauPRum6481dnbBjpDhO90kXXkZ+UnJKKe09C0aBmVqEmFApR38UGNx+EyFzn1oNXaOBiK7XMw9Uu1/jklFTsOHYV2poacLAyLqymF6rklFTcfRIK92/6JRQK0cDFFjfvv5K5zs0HIWjgIl3gNnSzzzUeAOISvkIgEEBHS6NwGl7IOB7EklNSEfQ4FB61pMeDey1bBOby+w24/woeLnZSyxq52SPwfggA4PW7SHyMjINHrawYHU0N1HA0R+C9kELvQ2FgHsSSU1Jx/+lb1Mu2X9SrYY3bD1/LXOf2wxDUqyF9fGhQyzbX+IioePhde4SurVwLr+EFwGtavjFixAioqqri7Nmz0NAQH6wrVqyIatWqoVKlSpg+fTq8vb2LtU162upQVhIiIiZRanlETCKsK8i+3uDg/15CV1sdp+e1hgACqCgLsflsMFYcyfp0cOtZBEasvYzn72NRvmwpTO5UDafmtkad8YeR8FX+pj6jYj4jLS0d+rpaUsv1dbXw/HW4zHXCI+OhXzZbfFkthEfGSS07+78HGDZzGxK/pqC8njb2/TEcemU0C7cDhSS3PBiU1cLzkI8y1wmPjIOBrrbUMnEeZE8Xf01Kwdw1x/BL0+rQKi2fRQvHg1hkTEIuedDGszzGg75ezrxl5uFjxr/ZYwz0cuZKXjAPYtGx4v2iXLZxXk5XCy/eyN4vIqLiUS5b3sqV1UJElOw+HjoTgNKl1NG8QfGfGgI40yIRFRWFv//+G15eXpKCJZOhoSF69uyJffv2QSQSST2XlJSEuLg4qUdJq+tgiHEdqmCCz1V4TD6KXr+fR7PqppjQsaok5nzQWxy7HoKHb6Lhd/cdOi86C53Sqmhf26LkGl5C6la3xoVtk+C7fgwautlhyG9bcz0P/m+XkpqGQdO3QCQCfp/cpaSbUyI4Hohyt/9UANo3rQ51NZUSeX0WLRmePXsGkUgEe3t7mc/b29sjOjoaERERUssXLVoEHR0dycPU1LRQ2xUZ9xWpaenQLyNdSOmX0UB4ttmXTNO71sD+y8+xw+8pHoVG42Tga8zbcxNj21eBQCD7deK+JOP5+1hYGmrLDihhumVKQ0lJmOPNIyIqHgbZPiVkMtDTQkS2i88iouNhoCfdx9IaarAw0UcNJ3OsnNYDykpC7MnluoiSllsewqPjYaCXWx60EZ7tU1OEjPjMguXthygc/GuE3M6yABwPmfTKaOaSh7gc/cpkoKeNiEgZecuIL5/xb/aY8MicuZIXzINYWR3xfpH9ottPUfHQ15XdZn1dLXzKlrdP0bLjA+6+wIs34ejW2q3wGl1ALFqyyT6T8j1Tp05FbGys5BEaGlqo7UlJS0fQy09wdzKSLBMIgAZOFRD4VPZ0n4aaMtKzdSMtY4EAsquW0mrKsDDUxoeYL4XT8EKmqqKMyramuHLrqWRZeno6/rn5FDWdzGWuU8PJAlduPpVadjngSa7xWdsVISk59WebXCRUVZRRxdYUlwOl83Al8AlqOsueJavpZI4rgdJ58A94LBWfWbC8DI3Awb9GQFdHfq9vAjgeMqmqKKOqnSn8A59IlqWnp+Ny4FO45DIeajlbSMUDwMUbj+HibA4AMDPWQ3k9bamYuIRE3HoYApfK5oXeh8LAPIipqijD2cYE/8u2X/zv9rNcvxKhuqM5/ndber+4EvhUZvy+kzfgbGtSotd4sWjJYGVlBYFAgODgYJnPBwcHo2zZstDX15darqamBm1tbalHYVvr+wB9Gtuim7sVbIx1sGJQXZRWU8auS+KB5j2iAWZ+czvzmVtv0L+pHX6pY4mK+prwcK6AaV1r4MytN0jPKMrm9q6FOvaGMNXXRC0bA+yY2ARp6ek49M/LQm9/YRnazQO7jl/DvlMBeBryAZN/P4AvX5PRrbX4grBf5+7EAu8TkvjBXdxx8XowvHf74VnIR/zucxp3H4eif8f6AIDPiUlYuO4Ebj0IQWhYFO4+DsWYBbvx4VMs2jSqWhJdzJdh3Rti5/Gr2HvyBp6++oCJS/fjy9dkdM+4MG7EnB2Yt/a4JH5IV3f4XQ/G2l3iPCzdeApBwaEY2Emch5TUNAyYuglBwW/gPacP0tJF+BgZh4+RcUhOkc83a4DjIZNXj0bYfvQq9vhex5NXHzBu8T58TkxCzzbiT8PDZm3HnNXHJPFDu3ngwrVHWL3zAp6GfMDiDScRFPwGgzu7AwAEAgGGdW+IZZvP4JT/PTx8/g7DZ++AYTkdtHKvUiJ9zA/mQWxQFw/s9b2Og6cD8CzkI6YvP4gvicno3FK8X4xdsAtL1md9vUX/Tg3gf+MxNuy9iOevP2Ll5jO4/yQUfX+pL7Xd+M9fcfLS3RKdZQF4Ia6Enp4emjZtirVr12Ls2LFS17V8+PABu3btQp8+fSDI7fxKETpy7RXKaatjWpcaMCijgfshkei08G9ExH4FAJiU05QUIwCw7FAQRCJgercaMNIthci4rzhz6w3m7bkliTHWLQ2f0R7Q1VLHp7ivuPH4I5pOP4HI+K/F3r/8at+kOiJjErB04ylERMXB0doEe1YMk0xjvvsYDaEw6/fj4myBtXP6YMmGU1i03hcWJvrYsngg7CtVAAAoCYV4/joc+09tRlRsAsrqlEZVu4o4unYU7CyNZLZBHnRoKs7Dko2nMr5EywT7Vg6XTFm//RAtNU5rVbbEurl9sWj9SSxYdwKWpgbYtnSQJA9h4TE4c+UBAKBh7yVSr3V0zUjUrWFdTD0rGI4HsV+a1cCnmAQsXH8S4ZHxcLYxxsE/R3wzHqIg/GY8uFaxxMb5/bDA2xfz1p6Apak+di4bAgerCpKY0X2a4EtiEsYu3IPYhES4VamEg396ldh1DPnBPIi1aVwNkTEJWLH5jORLF7cvGyq5SPn9x2ipPNR0tsCfM3tjmc8p/L7xJMxN9LFhwQDYZhvzJy7chkgkQtvG0l9KWtwEooKeD/kXe/bsGerUqQN7e3vMnz8fFhYWePjwISZOnIikpCRcv34durq6eW4jLi4OOjo6UGv9FwQq8ntNQHH4sKtfSTdBLigJi7/QlUdp2c9Z/kepqSiVdBNIzsQlyt8dm8UpPi4OViblEBsb+92zFTw99A1ra2vcvHkTlpaW6NKlCypVqoQhQ4agYcOGuHbt2ncLFiIiIio6PD2UjZmZGbZu3VrSzSAiIqJsONNCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECkG5pBvwb/XUpye0tbVLuhklyrDVkpJuglwIPT6ppJsgFzTVebghkkVbQ6Wkm1CyUvLff860EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLQpiy6ErcPllDsw9xqPloBW48+h1nvEn/O6gXrcFMPcYj4a9FuPC1Ye5xk5aug9GdUZjw75LhdzqwjeoTQ3c3e6FMN9JOPdnX1S3Nco1VllJiIk96+H21uEI852EK94D0bim5U9tU15sPXwFtTvPgVXjCWgz5PvjwfdiEDx6LoRV4wlo0ncJ/K49yhHzLOQD+k/ZCIfmU2DTdBJaDV6Odx+ji6oLhWLjfn9UbjsThnXHoEm/33HrYUie8UfP30atTvNgWHcM6nRbgLP/k94vRCIRFq7zhV3zaTCqNxbtvf7CizfhRdiDwsE8iDEPYv/mPLBoUQDHzt/G7D+PYPwAT/y9ZSIcrCqg+1hvfIqKlxkfeP8Vhs/ajh5t3HB260Q0b+CM/lM24fGL9zliT/nfxe2Hr2FYTqeou/HTOrjbY/7Qxliy8x94eG3Gg5fhOLSwG8qVKSUzfkY/d/RrVQ2T15yF26AN2HLyDnbM6gjnSuV/eJvy4PiF25i3+ijG9GuOUz4T4GBljN7j1+FTtOzxcPP+K/w6Zzu6tXLD6U0T4FnfGYOmbcLjl2GSmJB3n/DLiD9hVbE89v/5K85unYTRfT2hpqpcXN0qsMNnb2HGH0cweVALXNoxGU7Wxug4cg0ictkvbtx9iUEztqJXu9rw3zkFrdyroNeEDXj0PGu/WLX9PNbv88eKqd1wbssElNJQRceRa/A1KaW4ulVgzIMY8yD2b8+D3BUt/fr1g0AgkDz09PTQvHlz3Lt3L9d1QkJCcqzTrFkz3LlzRxLj4eEhFZP5GDZsmCTm2+Xa2tpwcXHBsWPHirS/+bF+7yX0bFsH3Vq7wdbCEEsndYGGmir2+F6XGe+z3x8NXe3g1bMxbMwNMXlIKzjbmmDzoStScWERMZix4hDWzOoNZWWl4ujKT/HqWAvbTwdh99l7ePLmE8atOo0vSano5VlFZnyXJk5YuecqzgW+wOsPMdjsexvnAl7g106uP7xNebBx3yV0b1MbXVu5wsbCEIsmdIa6uir2nbwhM37TQX941LLDsB6NYG1uiImDWsLJxgTbDmeNh6UbTqKRmwOme7WFk40JzI3LoVk9J5Qrq1Vc3Sqwtbv90Kd9HfRsWxt2lkZYMbUbSqmrYufxazLj1++9hMa17TGqdxPYWhhi+vDWqGJnio0H/AGIP02u23MREwZ4oqV7ZThZG8N7Th98+BSLk/53i7NrBcI8iDEPYv/2PMhd0QIAzZs3R1hYGMLCwnDhwgUoKyujdevW313v/PnzCAsLw99//42EhAS0aNECMTExkucHDx4s2W7mY+nSpVLb2LJlC8LCwnDz5k3UrVsXnTp1wv379wu7i/mWnJKKe09CUb+mjWSZUChEfRcb3HoQInOdmw9eob6LrdQyD1c7qfj09HSMnLMTw3s0gq2l/J8OUVEWoqq1ES7dCZEsE4kA/zuv4GJvLHMdNRUlfE1JlVr2NTkVbo4mP7zNkpackor7T9+iXo1s46GmTa5TwLcfhKDeN+MHANxrZY2H9PR0+F17BAtTffQc542qbWagzZAVOHM59w8KJS05JRVBj0PhUStrnAuFQrjXskXg/Vcy1wm4/woeLnZSyxq52SPwfggA4PW7SHyMjINHrawYHU0N1HA0R+C9kELvQ2FgHsSYB7H/Qh7ksmhRU1ODoaEhDA0NUbVqVUyZMgWhoaGIiIjIcz09PT0YGhqiZs2aWLZsGT5+/IgbN7I+fZYqVUqy3cyHtra21DbKlCkDQ0ND2NjYYN68eUhNTcXFixeLpJ/5ERXzGWlp6dDXlf7Eq6+rhfBcpvsiIuOhn+0Tsn5ZLYRHxkl+Xr3zApSUhBjUxb3wG10E9LRLQVlJiIjoz1LLI6I/w0C3tMx1/G6+gtcvtWBZoSwEAsCjujla17VFeV3NH95mSYuKlT0eypXVQsQ3v99vRUTFo1z2eF0tRESJ4z9FJ+BzYhLW7roAD1d77FoxDM0bVMaQGVtw7c7zounIT4qMSchlv9CWGuffCo+Mg76ejP0oI/5jxr/ZYwz0tHLdZkljHsSYB7H/Qh7k94R1hoSEBOzcuRNWVlbQ09PL93oaGhoAgOTk5B963dTUVGzatAkAoKqqmmtcUlISkpKSJD/HxcnnYP7W3ceh8Nnvj7NbJkIgEJR0c4rMFO9zWDW2BQI2DYUIwKv30dh99h56elYu6abJlXSRCADQrJ4TBnf1AAA4Wpvg5oNX2Hnsf6hdzaoEW0dElEUuZ1p8fX2hqakJTU1NaGlp4fjx49i3bx+Ewvw1NyYmBvPmzYOmpiZq1aolWb527VrJdjMfu3btklq3e/fu0NTUhJqaGsaOHQtzc3N06dIl19datGgRdHR0JA9TU9Mf63QudMuUhpKSMMdFVBFR8TDQlX29gb6eFiKyXZQZER0PAz3xrNKNuy/wKToBNX+ZDZP6Y2FSfyzefojCnL+OwuWXOYXa/sISGfcFqWnp0C8rPQOiX7Y0wqM+y14n9gt6zT4E47a/o3Kv1ag1cD0+JyYjJCzmh7dZ0nR1ZI+HT9Hx0NfTlrmOvq5Wjou2P0XFQ19XW7JNZSUhrM0NpWKszcrj/ceYwmt8IdIro5nLfhEnGefZGehpIyJSxn6UEV8+49/sMeGR8blus6QxD2LMg9h/IQ9yWbQ0bNgQQUFBCAoKQkBAADw9PdGiRQu8fv0aLVq0kBQcjo6OUuvVqVMHmpqaKFu2LO7evYt9+/ahfPmsO0V69uwp2W7mo23btlLbWLlyJYKCgnD69Gk4ODjAx8cHurq6ubZ16tSpiI2NlTxCQ0MLNReqKsqobGuKf249lSxLT0/HPzefooaTucx1ajpZ4J+bT6WWXQ54Ionv1NwFftsn4fzWiZKHYTkdePVohD0rh8nYYslLSU1H0LMwuFc1lywTCIAGVc0RGPwuz3WTUtIQFpkAZSUh2tSzxelrT396myVFVUUZzjYm+N+tZ5Jl6enp+OfWU9RwNJe5TnUnc6l4ALhyM2s8qKooo4p9RbzMdgvjy9AIGBuWLdT2FxZVFWVUtTOFf+ATybL09HRcDnwKF2cLmevUcraQigeAizcew8XZHABgZqyH8nraUjFxCYm49TAELpXNC70PhYF5EGMexP4LeZDL00OlS5eGlVXWlLSPjw90dHSwceNG+Pj4IDExEQCgoqIitd6+ffvg4OAAPT09lClTJsd2dXR0pLYri6GhIaysrGBlZYUtW7agZcuWePToEQwMDGTGq6mpQU1NrYA9LJih3Twwev4uVLGriKoOFbFxnz++fE1Gt9biu2BGzt0JQ30dTB/eBgAwqIs7fvH6E+t2+6FxHUccO38bdx+H4vfJXQGIP1nr6kjPLigrK0FfTxtWZuUhr9YeCsDaiW1w51kYbj9+j+G/1EJpdRXs+lt8waj3xDYIi4zH3M2XAAA17CrASE8L9198RIVyWpjcuz6EQgFW7b+e723Ko8FdPTBu4W5UtjNFVfuK2HTAH4mJyejSUjwexszfCcNyOpgyTDweBnZyR+eRf2H93otoXNsBxy/cxr3HoVg8satkm0O7N8KIWdvgWqUSale3gv+Nxzh/9SH2//lrifQxP7x6NILXnB2oZl8R1R3N4b3nIj4nJqFnGzcAwLBZ22Gkr4NZv7YDIN6PWg/9A6t3XkCzeo44fPYWgoLf4I9p3QGI7x4c1r0hlm0+A0tTfZgZ62HhupMwLKeDVu7yezcZ8yDGPIj92/Mgl0VLdgKBAEKhEImJiTA2zv2uDlNTU1SqVKnQXrdWrVqoUaMGFixYgFWrVhXadguqXZPqiIxJwNKNpxARFQdHaxPsXjFMMr3/7mM0hMKsa1NcnC2wdk4fLNlwCovW+8LCRB9bFg+EXaUKJdWFQnHEPxjldEphWp8GMChbGvdffkSn6fsQESM+lWNioC25PgMA1FSUMb2fO8yNyuBzYjLOBbzAsCXHEfc5Kd/blEdtG1dHVMxnLN90GhFRcXCwMsaOZUMlF9+9+xgtda1STWcL/DWrD37feBJLN/jC3EQfPgsHwu6bu8ZaNKiMhRM6Y83O85i56jAqVdTH+nn9Uatyzi/jkxe/NKuBTzEJWLj+JMIj4+FsY4yDf46QTFm//RAF4Td5cK1iiY3z+2GBty/mrT0BS1N97Fw2BA5WWfvF6D5N8CUxCWMX7kFsQiLcqlTCwT+9oK6mkuP15QXzIMY8iP3b8yAQib45ysuBfv364ePHj9iyZQsAIDo6GqtXr4a3tzf8/Pzg4eGRY52QkBBYWFjgzp07qFq1qsztenh4wMbGBnPnzpVarqamhrJlxVPgAoEAR44cQfv27SXPnz59Gh06dMCLFy/yLJgyxcXFQUdHB68/ROW4M+m/xqjVkpJuglwIPT6ppJsgFzTVFeIzEhEVs7i4OJTX00FsbOx33zfl8pqWM2fOwMjICEZGRnB1dUVgYCAOHDggs2ApiI0bN0q2m/no3r17nus0b94cFhYWWLBgwU+9NhEREf0cuZtpUXScacnCmRYxzrSIcaaFiGRR+JkWIiIiouxYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBCUS7oB/1ZCgQBCgaCkm1Gi3vtOLukmyIUK7VeWdBPkQvSpCSXdBCK59DU5raSbUKIK0n/OtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi0KYvPBy6jZYTYquo9D84HLcfvh6zzjj1+4g7pd56Oi+zi491yE81cfSj3/u88p1O06H+YNJ8Cm2WR0Grkatx6GFGEPCseWQ1dQq+McWDQcj1aDV+DOo7zzcMLvDup3XwCLhuPRqPdiXMiWh29NXroPFeqOxsZ9lwq51YVvUOuquLtlMMKOjsG5lT1R3cYwz/hh7aojYMMAvD8yGg+2DcGCwR5QU1GSPK+poYKFQxri3tYheH9kNP5e1h3VrPPepjzYuN8fldvOhGHdMWjS7/fvjuGj52+jVqd5MKw7BnW6LcDZ/0mPB5FIhIXrfGHXfBqM6o1Fe6+/8OJNeBH2oHAwD2LMg9iWQ1fg0nEOzBuOR8t8HifrdV8A84bj0fA7x8lJS/fBqO5obCih4ySLFgVw9PxtzPrzCMYPbI5zWyfC0doY3cauRURUvMz4wHsvMWzWNvRoUxvnt01CiwaV0W+yD4JfvJfEWJoaYOH4zri0cwqOrxsDUyNddB29Fp+iZW9THhw7fxtz/jqCcQM88ffmiXCwqoAe47xzbXPg/Vfwmr0d3Vu74eyWiWhe3xkDpm7C45fvc8Se9r+LWw9fw7CcTlF346d1aGCL+YM9sGT3NXiM3IEHL8NxaF4nlNMpJTO+k4cdZvVvgKW7r8J16BaM/ONvdGhgh9/61ZfErBrtCY9qZhi27BTqem2D353XOLqwM4z0NIurWwV2+OwtzPjjCCYPaoFLOybDydoYHUeuyXW/uHH3JQbN2Ipe7WrDf+cUtHKvgl4TNuDR86zxsGr7eazf548VU7vh3JYJKKWhio4j1+BrUkpxdavAmAcx5kHs2PnbmP3XEYz/5jjZ/TvHyeGzt6PHN8fJ/rkcJ0/538XtEj5OKkTR0q9fP7Rv3z7X5z08PCAQCCAQCKCurg4HBwesXbtW8vzWrVslz3/7UFdXl3qNzOUqKiqwsLDApEmT8PXr16LsWr6s23MRvdrWQffWbrC1MMLvk7pAQ00Ve3yvy4zfsN8fDV3tMaJXY9iYG2LK0FZwtjXB5oNXJDEdPWvCvZYtzI3Lwc7SCHNHd0D8569SO6y82bDvEnq0qYNurdxgY2GIJRPzzoPPfn80dLWDV8/GsDY3xKQhreBsY4It3+QBAMIiYjBj5SGsmdUbyspKMrclT7w61MT2M/ex+9wDPAmNxLjV5/AlKQW9mjnJjK9lb4wbj97h4KXHCA2Pw8U7r3HI/zFqZMzOqKsqo21dG8zefBlXH7zFq7AYLNl1FS/fR2NAqyrF2bUCWbvbD33a10HPtrVhZ2mEFVO7oZS6KnYevyYzfv3eS2hc2x6jejeBrYUhpg9vjSp2pth4wB+A+FP1uj0XMWGAJ1q6V4aTtTG85/TBh0+xOOl/tzi7ViDMgxjzILZ+3yX0zDhO2loYYmkBjpM25oaYnHGc3Cynx0mFKFryY/DgwQgLC8OjR4/QpUsXjBgxAnv27JE8r62tjbCwMKnH69fSU2bNmzdHWFgYXr58iZUrV2L9+vWYNWtWcXdFSnJKKu49CUV9F1vJMqFQiAYutrj54JXMdW49CEEDFxupZQ1d7XONT05JxY6jV6GtqQFHa+PCa3whyspDVr+EQiHq17TBrQchMte59fAV6te0lVrm7monNWWcnp6OUXN3YniPRrC1NCqKphcqFWUhqlqVx6WgrLErEgH+QW/gYldB5joBwe9Q1aq85BSSmaEOmta0wLlA8XhQVhJAWUmIr8mpUut9TU6Fm4NJEfXk5ySnpCLocSg8aknvF+61bBF4X/Y4D7j/Ch4udlLLGrnZI/B+CADg9btIfIyMg0etrBgdTQ3UcDRH4L2QQu9DYWAexJgHsR85Tt6UcZz0kHGcHCknx0nlEn31QlSqVCkYGooPyrNnz8bu3btx/PhxdO/eHQAgEAgkz+dGTU1NEmNqaoomTZrg3LlzWLJkSdE2Pg9RMZ+RlpYOfV0tqeX6ulp49vqjzHXCI+Ogr6udIz48Unp68Ow/DzB05lYkfk1BeT1t7F/lBb0y8nk6ILc8lNPVwvNczjFHRMajnIy8hUfGSX5es/MClJSEGNjZvfAbXQT0tDWgrCRERPRnqeURMZ9hbaorc52Dlx5DV1sDp3/vDoEAUFFWwuaTQVix/wYAICExBQGP3mFi99p4GhqJ8Jgv6ORuBxe7CngZFlPUXfohkTEJuewX2ngWksd+oZf7ePiY8W/2GAM96TEjT5gHMeZBLK/3i7yOk7Liv+3j6ozj5CA5OE7+a2ZastPQ0EBycvIPr//gwQNcvXoVqqqqecYlJSUhLi5O6qEo6tawht+2yfDdMAYN3ewxeMaWXM///hvdexwKnwP++GN6TwgEgpJuTpGp62yKcV3cMGHteXiM2oFe846imYslJnR3k8QMXXYKAgEQvHM4Ph4biyFtq+OQ/2Okp4tKsOVEVNLuZhwnV8nJcfJfM9OSKS0tDXv27MG9e/cwZMgQyfLY2FhoakrPItSvXx+nT5+W/Ozr6wtNTU2kpqYiKSkJQqEQq1evzvP1Fi1ahDlz5hRuJ76hW6Y0lJSEOYqJiKh4GGT7BJDJQE8bEVFx340vraEGC1N9WJjqo6aTBdw6z8PuE9cwum+zwu1EIcgtD5+icn5KyKSvp4VPMvMmnoW6cfcFPkUnwKXjbMnzaWnpmLP6KDbu90fAoZI9NShLZFwiUtPSoV+2tNRy/TKlER71WeY603vXxX6/R9jx930AwKOQTyitroKVI5th+d7rEImAkA+xaD15H0qpqUCrlCo+Rn/Gpimt8fpDbJH36UfoldHMZb+Ik/x+szPQ00ZEZO7joXzGvxGR8VIXGoZHxsPZRj5PkzEPYsyDWJ7vF3kcJ2W/v0gfJ2vmcpwMLObjpELNtOzatQuampqSx5UrWRcKrV27FpqamtDQ0MDgwYMxduxYDB8+XPK8lpYWgoKCpB4+Pj5S22/YsCGCgoJw48YN9O3bF/3790fHjh3zbNPUqVMRGxsreYSGhhZqn1VVlFHZ1hRXbj6VLEtPT8eVm09Q08lC5jo1nMyl4gHAP+BxrvGS7YrSkZySmmdMScnMwz/Z8vDPraeo4WQuc50ajha4cks6D5cDn6CGozi+Y3MXXNg+Cee2TpQ8DMvpYHiPRti9YlhRdeWnpKSmI+j5R7hXqShZJhAADapWROBj2RdRa6gpI10kPWOSljGDkv2T05ekFHyM/gwdTTU0rm6OU9efF3IPCoeqijKq2pnCP/CJZFl6ejouBz6Fi7PscV7L2UIqHgAu3ngMF2dzAICZsR7K62lLxcQlJOLWwxC4VDYv9D4UBuZBjHkQ+5HjZE1HC/yTx3GyU3MX+G2fhPNbJ0oehuV04NWjEfaUwHFSoWZa2rZtC1dXV8nPxsZZF4327NkT06dPh4aGBoyMjCAUStdjQqEQVlZWeW6/dOnSkpjNmzejSpUq2LRpEwYOHJjrOmpqalBTU/uR7uTbsO4NMWreTlS1M0U1RzNs2HsJX74mo1trcS5+nbMDhvo6mOHVFgAwpIs72nv9Ce/dfmhSxxFHz9/C3cehWDalGwDgc2IS/th6Fp71nVBeTwdRsQnYfPAKPkTEok2jakXal58xpKsHxizYhSp2FVHNoSI27vcX56GVOA+j5u2EYTkdTBveBgAwqIs7Oo74E+v2+KFxHUccO38b9x6H4vfJXQEAujqloasjPWOhrKwEA11tWJmVL97OFcDaIzexdlwL3Hn2EbefhmF4uxooraaCXeceAAC8x7dAWGQC5m4VF/VnAl7Cq0MN3HvxETeffIBlhTKY1rsuzgS8kJz+aVTdHAIB8OxtNCwrlMHcAe54+jZKsk155NWjEbzm7EA1+4qo7mgO7z0X8TkxCT3biE97DZu1HUb6Opj1azsAwNBuHmg99A+s3nkBzeo54vDZWwgKfoM/pmVd9zase0Ms23wGlqb6MDPWw8J1J2FYTget3OX3LirmQYx5EBva1QOjM46TVWUcJ0dmHCenf3Oc/CXbcfJuPo6T+iV0nFSookVLSwtaWrKnuHR0dL5blBSEUCjEtGnTMG7cOPTo0QMaGhqFtu2Cat+kOiKjE7DU5xTCI+PgaG2CPSuHwyDjYtt3H6MhFGZ9YnapbAnvOX2xeMNJLFx3AhamBti6ZBDsK4nvLlESCvH89UfsPxWAqNgElNUpjar2FXHMezTs5PgOmnZNqiMyJgG/+5xCRJQ4D7uWD5NcdPzuYzSE38wcuDhbYM3sPliy4RQWr/eFhYk+Ni8aCDtL2XfZKIojl5+gnHYpTOtdFwZlS+H+ywh0mnkQETFfAAAm+tpS16Is23MNIpEI0/vUg5GeJiJjE3Em4AXmbftHEqNdWg0z+9VHhXKaiI7/ihP/e4b5264gNS292PuXX780q4FPMQlYuP5kxpS9MQ7+OUIyrf32Q5TUeHCtYomN8/thgbcv5q09AUtTfexcNgQOVlnjYXSfJviSmISxC/cgNiERblUq4eCfXlBXUyn2/uUX8yDGPIhlHieXfnOc3P2d4+TajOPkoozj5BY5Pk4KRCKR3F9p169fP8TExODo0aMyn/fw8EDVqlXxxx9/yHx+69atGD16NJ48eZLjOQMDAwiFQpmvkZqaCnNzc4wZMwYTJkzIV1vj4uKgo6OD0I/R0NaWfS71vyKNF3ECACq0X1nSTZAL0afytw8R/dd8TU4r6SaUqLi4OJgZ6SI2Nva775sKdU3Lz4iLi4ORkVGOR3h47l/JrKysjF9//RVLly7F58+yL3IkIiKi4qEQMy2KhDMtWTjTIsaZFjHOtBDJxpkWzrQQERHRvwyLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFwKKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFwKKFiIiIFIJySTfg30pJKICSUFDSzShRqsqsiQEg+tSEkm6CXCjb7q+SboJcCNkzrKSbIBc0VJVKuglyQ+U/fqwsSP//25kiIiIihZGvmZbjx4/ne4Nt27b94cYQERER5SZfRUv79u3ztTGBQIC0tLSfaQ8RERGRTPkqWtLT04u6HURERER5+qlrWr5+/VpY7SAiIiLKU4GLlrS0NMybNw/GxsbQ1NTEy5cvAQC//fYbNm3aVOgNJCIiIgJ+oGhZsGABtm7diqVLl0JVVVWy3MnJCT4+PoXaOCIiIqJMBS5atm/fjg0bNqBnz55QUsq6z75KlSp4/PhxoTaOiIiIKFOBi5Z3797Bysoqx/L09HSkpKQUSqOIiIiIsitw0eLg4IArV67kWH7w4EFUq1atUBpFRERElF2Bv8Z/5syZ6Nu3L969e4f09HQcPnwYT548wfbt2+Hr61sUbSQiIiIq+ExLu3btcOLECZw/fx6lS5fGzJkzERwcjBMnTqBp06ZF0UYiIiKiH/uDifXr18e5c+cKuy1EREREufrhv/J88+ZNBAcHAxBf51KjRo1CaxQRERFRdgUuWt6+fYvu3bvjf//7H8qUKQMAiImJQZ06dbB3716YmJgUdhuJiIiICn5Ny6BBg5CSkoLg4GBERUUhKioKwcHBSE9Px6BBg4qijUREREQFn2nx9/fH1atXYWtrK1lma2uLv/76C/Xr1y/UxhERERFlKvBMi6mpqcwvkUtLS0OFChUKpVFERERE2RW4aPn9998xcuRI3Lx5U7Ls5s2bGD16NJYtW1aojSMiIiLKlK/TQ2XLloVAIJD8/PnzZ7i6ukJZWbx6amoqlJWVMWDAALRv375IGkpERET/bfkqWv74448ibgYRERFR3vJVtPTt27eo20FERESUpx/+cjkA+Pr1K5KTk6WWaWtr/1SDiIiIiGQp8IW4nz9/xq+//goDAwOULl0aZcuWlXoQERERFYUCFy2TJk2Cn58fvL29oaamBh8fH8yZMwcVKlTA9u3bi6KNRERERAU/PXTixAls374dHh4e6N+/P+rXrw8rKyuYmZlh165d6NmzZ1G0k4iIiP7jCjzTEhUVBUtLSwDi61eioqIAAPXq1cPly5cLt3VEREREGQo802JpaYlXr16hYsWKsLOzw/79+1GrVi2cOHFC8gcUqfBtOnAZq3ddQHhkHBytjbF4fCdUdzTPNf7YhTtYtN4XoWFRsDTVx8wR7dC0rqPked+LQdh6+H+4+/gNouO+4OKOyXC2kf8/drlxvz/+2inOg5O1MZZM7IwaeeTh6PnbWLjuJN6ERcLSVB+zR7ZHs2/yIBKJsGj9SWw/ehWxCYlwrWyJ5VO6olJFg2LozY9jHsQGtXTGyPbVYVC2FB6EfMLkDZdx+9nHXOOHtamCAS2cYVJOC1HxiTh29Tnmbr+GpJQ0AMDdDX1RsXzOmwl8Tt3DxPX+RdaPn7X9yD9Yv9cPEVHxsK9UAXNG/4Kq9ma5xp+8GITlm0/j7YcoWBjrY8qw1mjo5iB53tx9rMz1pg5rg6HdGxV6+wvL5oOXsXaXH8Kj4uBgZYyF4zqhumPueTh+4Q6WbDiJ0A9RsDDRx28j2qJJnaz94nefUzh67jbehcdAVUUJlW1NMXVY6zz3NXnwb36/KPBMS//+/XH37l0AwJQpU7BmzRqoq6tj7NixmDhxYqE3kIAj527ht1VHMHFgC/htmwRHK2N0Hr0WEVHxMuMD7r3EkN+2omeb2ri4fTJaNqiMPpM2IvjFe0nMl8RkuFaxxMxf2xVXN37a4bO3MOOPI5g8qAUu7ZgMJ2tjdBy5Jtc83Lj7EoNmbEWvdrXhv3MKWrlXQa8JG/DoeVYeVm0/j/X7/LFiajec2zIBpTRU0XHkGnxNyvmnKuQF8yDWoZ415g+ojyX7AuAxbi8evPqEQ7PbopyOhsz4Tg1sMKtPHSzdGwDXX3di5F8X0KGeNX7rXVsS02jCPtj23SR5tJ95FABw9H/Pi6NLP+SE3x3MX3MUo/t64uTG8XCoVAF9JqzHp2jZ4+HWg1cYNW8HurZ0xamNE9CsvhOGTN+MJy/DJDEBh+dIPZZO7gaBQIAW7pWLq1sFdvT8bcz68wjGD2yOc1snwtHaGN3G5n6cDLz3EsNmbUOPNrVxftsktGhQGf0m+0gdJy1NDbBwfGdc2jkFx9eNgamRLrqOXptrbuXBv/39osBFy9ixYzFq1CgAQJMmTfD48WPs3r0bd+7cwejRowu0rX79+kEgEEgeenp6aN68Oe7du/fddR8+fIguXbpAX18fampqsLGxwcyZM/HlyxepOHNzc8n2S5UqBWdnZ/j4+OTYnkgkwsaNG1G7dm1oa2tDU1MTjo6OGD16NJ4/L9kDlveei+jdrjZ6tHGDraURlk/pCg11Vew+cU1m/Pp9l9DIzR4jezeBjYUhpg5rjcq2pvA5kHX6rkvLWpg4qAXcXWxlbkMerd3thz7t66Bn29qwszTCiqndUEpdFTuP55KHvZfQuLY9RvVuAlsLQ0wf3hpV7Eyx8YD4E7NIJMK6PRcxYYAnWrpXhpO1Mbzn9MGHT7E46X+3OLtWIMyDmFe7qth+9iF2XwjGk9BojPO+iC9JqejVxEFmfC07I9wIDsPBy08RGh6Pi0GhOHT5GWpYl5fERMZ9RXjMF8nDs6Y5XobF4H8P3hVXtwrMZ/8ldGtdG11ausLa3BALxneGhroq9p+6ITN+88HLcK9lh6HdG8HKvDzGD2wJRxsTbDtyRRJjoKct9Tj3vweoXc0KFSuUK65uFdi6PRfRq20ddG/tBlsLI/w+qQs01FSxx/e6zPgN+/3R0NUeI3o1ho25IaYMbQVnWxNsPpiVh46eNeFeyxbmxuVgZ2mEuaM7IP7zV6mCX978298vCly0ZGdmZoZffvkFlSv/WAXevHlzhIWFISwsDBcuXICysjJat26d5zrXr1+Hq6srkpOTcfLkSTx9+hQLFizA1q1b0bRp0xzfHTN37lyEhYXhwYMH6NWrFwYPHozTp09LnheJROjRowdGjRqFli1b4uzZs3j06BE2bdoEdXV1zJ8//4f6VhiSU1Jx93Eo3GtlDRahUAh3F1sE3g+Ruc7N+yE5BldDNzvcvP+qKJtapJJTUhH0OBQe2fNQyxaBufQr4P4reLjYSS1r5GYvydvrd5H4GBkHj1pZMTqaGqjhaI7AeyGF3ofCwDyIqSgLUbWSAS7dDZUsE4kA/7uhcLE1lLlOwOMwVK1kgOoZRYpZeW00rWGGc7de5/oaXTxsset8cOF3oJAkp6TiwdO3qFvDRrJMKBSibg1r3H4ou193HoZIxQNAAxfbXOMjouJx8dojdG3pWngNL2TJKam49yQU9V2k94sGLra4+UD2fnHrQQgauEjnoaGrfa7xySmp2HH0KrQ1NeBobVx4jS9E/4X3i3xd0/Lnn3/me4OZszD5paamBkND8UHG0NAQU6ZMQf369REREQF9ff0c8SKRCAMHDoS9vT0OHz4MoVBcd5mZmcHGxgbVqlXDypUrMXnyZMk6WlpakteYPHkyli5dinPnzqFFixYAgH379mHv3r04duwY2rZtK1mvYsWKcHNzg0gkKlCfClNkzGekpaVDX1f6PLu+rhaevZZ97j48Mg76ulpSywx0tRAeKb9Tmt8TGZOQkQfpfunrauNZSB550Mser4XwyDgAwMeMf7PHGOhlxcgb5kFMT1sDykpCRMRIz6xGxHyBtYns74s6ePkpdLXVcXpRRwgEgIqyEjafvo8VB2/KjG/lagmd0mrY7Se/RUt0rPj4UK5stt9vWS28eBMuc52IqHiZ8Z+iZP+uD50JQOlS6vBsIL+nhqIkx8mc4zzv42TO42r24+TZfx5g6MytSPyagvJ62ti/ygt6ZTQLtwOF5L/wfpGvomXlypX52phAIChw0fKthIQE7Ny5E1ZWVtDT05MZExQUhEePHmH37t2SgiVTlSpV0KRJE+zZs0eqaMmUnp6OI0eOIDo6GqqqqpLle/bsga2trVTBkr1fuUlKSkJSUpLk57g4+TzIE/3X1XUyxrhONTFh/SXcevoRFkY6WDyoASZ0ccGy/YE54ns1dcD5W6/xIepzCbRWfuw/HYD2TapDXU2lpJtSIurWsIbftsmIjE3AzmPXMHjGFpz2GZ/jjZ6KR76Kllevim6ayNfXF5qa4qr18+fPMDIygq+vb46CJNPTp08BAPb29jKft7e3xz///CO1bPLkyZgxYwaSkpKQmpoKXV1dDBo0SGqbtrbS02NjxoyRXPtSpkwZvH37VubrLVq0CHPmzMlHT3+MXpnSUFISIiLbp6CIqHgY6Mr+kwkGeto5LroKj4qHgZ7i7mR6ZTQz8iDdr4ioOBjo5ZGHyOzx8ZL48hn/RkTGw7CcjiQmPDJebu+kYh7EIuMSkZqWDv0ypaSW65cphfDoLzLXmd7DDfsvPcGOc48AAI9eR6K0mgpWjmiI5QcC8e2Eqqm+Fjwqm6L34lNF1ofCUFZHfHzIfmFoRHR8jk/bmfR1tWTGl5MRH3D3BV6+CcfqWX0Kr9FFQFdynJQ1zmUf98THSRnH1WzxpTXUYGGqDwtTfdR0soBb53nYfeIaRvdtVridKAT/hfeLn76m5Wc1bNgQQUFBCAoKQkBAADw9PdGiRQu8fv0aLVq0gKampuSi2G8V5JTNxIkTERQUBD8/P7i6umLlypWwsrLKc53p06cjKCgIM2fOREJCQq5xU6dORWxsrOQRGhqaa+yPUFVRRhU7U1wOfCpZlp6ejsuBT+HibC5znZrO5rh886nUMv+AJ6jpbFGobStOqirKqGpnCv/AJ5JlWXmQ3a9azhZS8QBw8cZjSd7MjPVQXk9bKiYuIRG3HobApbJ5ofehMDAPYimp6Qh6EQ73yllFlUAANKhsisAnH2Suo6GmjPR06eNGWnp6xrrSs6k9GtsjIjYRZ2+GFG7DC5mqijKcbExw9Zb08eHq7We53upbzdFcKh4A/rn5VGb8vlM34GxrAgcr+byGI5OqijIq25riyk3pPFy5+QQ1nWTvFzWczKXiAcA/4HGu8ZLtitKRnJL6840uAv+F94uf+oOJhaF06dJSBYSPjw90dHSwceNG+Pj4IDExEQCgoiKemrSxEV84FRwcjGrVquXYXnBwsCQmU7ly5WBlZQUrKyscOHAAzs7OqFmzJhwcxHcZWFtb48kT6YO6vr4+9PX1YWCQ9/dUqKmpQU1NrYC9Lpjh3Rvi17k7UdW+Iqo7mGHd3kv48jUJ3Vu7AQC8Zm+HkX4Z/DZCfHpraFcPtB22Cmt2XUCzuo44fO42goLfYMXUbpJtRsd+xtuP0fgQEQsAeJ5xvtNAT1vyyVveePVoBK85O1DNviKqO5rDe89FfE5MQs824jwMm7UdRvo6mJVxW97Qbh5oPfQPrN55Ac3qOeLw2VsICn6DP6Z1ByB+oxrWvSGWbT4DS1N9mBnrYeG6kzAsp4NW7lVKrJ/fwzyIrT0WhLWjm+DO83DcfvYRw9tURWl1Zew6L55J8R7TFGGRCZi7Q3zXxJnAV/BqVw33XkXg5pOPsDTSwbSebjgTGCJVzAgEQM/G9th78THS0kvuerb8GtTFA+MX7YaznSmq2plh00F/fElMRucW4gtnxy3YhfL6Opg8RHyDw4BODdB11Gps3HcRDd0ccMLvDu4/CcWiCV2kthv/+StOXbqL6V6yT5vLm2HdG2LUvJ2oameKao5m2LD3Er58TUa31uI8/DpnBwz1dTAjoz9Durijvdef8N7thyZ1HHH0/C3cfRyKZVPEx8nPiUn4Y+tZeNZ3Qnk9HUTFJmDzwSv4EBGLNo1yvvfIi3/7+0WJFy3ZCQQCCIVCJCYmwtg4Z3VftWpV2NnZYeXKlejWrZvUaaS7d+/i/PnzWLRoUa7bNzU1RdeuXTF16lQcO3YMANC9e3f06NEDx44dQ7t2JX8fenYdmtZAZEwCFm84ifDIeDjZGGP/H16S6f23H6MhFGZ9UqxV2RLr5/XDwnW+WODtC0tTfWxfOhj2lSpIYs5cuY+R83ZJfh48YysAYOKgFpg8uGXxdKyAfmlWA59iErBw/cmMUxfGOPjniKw8fIiC8JtPzK5VLLFxfj8s8PbFvLUnYGmqj53LhsDBKisPo/s0wZfEJIxduAexCYlwq1IJB//0kuvz98yD2JF/nqGctgam9XCFQdnSuP8qAp3mHEdErPiDjkk5TaliZNl+8Smg6T3dYKSrici4RJwJfIV5O6VvBfWoYgpTA23szCh+5F2bRtUQFZOAlZvPICIqDvZWxtj2+1DJNRfvwqMh+Ob4UMPJAqt+643lm07h940nYW6ijw0LBsDW0khquycu3IZIJELbxtWLtT8/qn2T6oiMTsBSn1MZX6pmgj0rh0tOi7zLdpx0qWwJ7zl9sXjDSSxcdwIWpgbYumSQ5DipJBTi+euP2H8qAFGxCSirUxpV7SvimPdo2GXLlTz5t79fCEQleGtMv3798PHjR2zZsgUAEB0djdWrV8Pb2xt+fn7w8PCQud7Vq1fRtGlTNGvWDFOnToWhoSFu3LiB8ePHw9TUFH5+fpLZD3Nzc4wZMwZjxoyRrP/o0SM4OTkhICAANWvWhEgkQpcuXeDr64upU6fC09MT5cuXx+vXr7F48WIEBAQgMjIyX32Ki4uDjo4O3kfEQFtbPmcsiouSMPcLmOm/p2y7v0q6CXIhZM+wkm6CXNBQVSrpJsiN//qxMi4uDhX0yyA2Nva775slfk3LmTNnYGRkBCMjI7i6uiIwMBAHDhzItWABgDp16uD69etQUlJCixYtYGVlhalTp6Jv3744d+7cd0/XODg4oFmzZpg5cyYA8ezOvn378Mcff+DUqVNo3LgxbG1tMWDAAJiamua4sJeIiIiK3w/NtFy5cgXr16/HixcvcPDgQRgbG2PHjh2wsLBAvXr1iqKdCoMzLVn+658eSBpnWsQ40yLGmZYs//VjZZHOtBw6dAienp7Q0NDAnTt3JN9REhsbi4ULF/5Yi4mIiIi+o8BFy/z587Fu3Tps3LhRckcPANStWxe3b98u1MYRERERZSpw0fLkyRM0aNAgx3IdHR3ExMQURpuIiIiIcihw0WJoaCjzrx7/888/sLS0LJRGEREREWVX4KJl8ODBGD16NG7cuAGBQID3799j165dmDBhAoYPH14UbSQiIiIq+JfLTZkyBenp6WjcuDG+fPmCBg0aQE1NDRMmTMDIkSOLoo1EREREBS9aBAIBpk+fjokTJ+L58+dISEiAg4OD5I8eEhERERWFH/4af1VVVcnf7iEiIiIqagUuWho2bJjjL6J+y8/P76caRERERCRLgYuWqlWrSv2ckpKCoKAgPHjwAH379i2sdhERERFJKXDRsnLlSpnLZ8+ejYSEhJ9uEBEREZEshfYHE3v16oXNmzcX1uaIiIiIpBRa0XLt2jWoq6sX1uaIiIiIpBT49NAvv/wi9bNIJEJYWBhu3ryJ3377rdAaRkRERPStAhctOjo6Uj8LhULY2tpi7ty5aNasWaE1jIiIiOhbBSpa0tLS0L9/fzg7O6Ns2bJF1SYiIiKiHAp0TYuSkhKaNWvGv+ZMRERExa7AF+I6OTnh5cuXRdEWIiIiolwVuGiZP38+JkyYAF9fX4SFhSEuLk7qQURERFQU8n1Ny9y5czF+/Hi0bNkSANC2bVupr/MXiUQQCARIS0sr/FYSERHRf16+i5Y5c+Zg2LBhuHjxYlG2h4iIiEimfBctIpEIAODu7l5kjSEiIiLKTYGuacnrrzsTERERFaUCfU+LjY3NdwuXqKion2oQERERkSwFKlrmzJmT4xtxiYiIiIpDgYqWbt26wcDAoKjaQkT/Yh8OepV0E+SCYbuVJd0EuRB2dGxJN0FuCP/jV15kXjObH/m+poXXsxAREVFJynfRUpBKiIiIiKiw5fv0UHp6elG2g4iIiChPBf4afyIiIqKSwKKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFwKKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCEol3QDKH82HbiM1bsuIDwyDo7Wxlg8vhOqO5rnGn/swh0sWu+L0LAoWJrqY+aIdmha11HyvO/FIGw9/D/cffwG0XFfcHHHZDjbmBRDT37Oxv3++GunOA9O1sZYMrEzauSRh6Pnb2PhupN4ExYJS1N9zB7ZHs2+yYNIJMKi9Sex/ehVxCYkwrWyJZZP6YpKFQ2KoTc/jnkQ23zoCtbu8kNEVBwcrIyxYFxHVHcwyzX+uN8dLN1wCqEfomBhoo8ZXm3QpE5WHn73OY1j52/jXXgMVFWUUNnWFFOHtspzX5MHg1pXxciOLjAoWxoPXkVgsvcF3H76Idf4Ye2qY0CrqjDR10JUXCKO/fMUc7deQVJKGgBAU0MF03rXQ+s61iino4H7L8IxZf1F3HmW+zblwZZDV7B29zfjYWxHVMtjPJzwu4MlG0/hbeZ4GN4Gjb8ZD9+atHQfdhy7ijmjOmBIV48i6kHh2HTwMtbs9EN4VBwcrYyxaHwnVHfMPQ/HLtzB4g0nJe8Xv41oi6YZeUhJTcOidb44f+0RXr+LhJamOtxdbPGbV1sY6usUV5ckONOiAI6cu4XfVh3BxIEt4LdtEhytjNF59FpERMXLjA+49xJDftuKnm1q4+L2yWjZoDL6TNqI4BfvJTFfEpPhWsUSM39tV1zd+GmHz97CjD+OYPKgFri0YzKcrI3RceSaXPNw4+5LDJqxFb3a1Yb/zilo5V4FvSZswKPnWXlYtf081u/zx4qp3XBuywSU0lBFx5Fr8DUppbi6VWDMg9jR87cx+88jGD/AE2e3TISjVQV0H+udax4C77/C8Fnb0b2NG85tnYgWDZzRf8omqf2iUkV9LBzfCZd2TMYx79EwNdJF1zHe+BSdUFzdKrAODWwxf7AHluy+Bo+RO/DgZTgOzeuEcjqlZMZ38rDDrP4NsHT3VbgO3YKRf/yNDg3s8Fu/+pKYVaM94VHNDMOWnUJdr23wu/MaRxd2hpGeZnF1q8COnb+N2X+Jx8PfmyfCwaoCuo/zxqfoPMbD7O3o0doNZ7dMRPP6zug/dRMev3yfI/aU/13cfvgahuWK/026oI6cu42Zq45gwqDmuLBtIhytjdFlTN7vF0NnbkPPNrXht20SWjSojL6TfCT7ReLXZNx78hbj+nviwraJ2Lp4IJ6/DkeviRuKs1sSclm09OvXD+3bt88zJjExEbNmzYKNjQ3U1NRQrlw5dO7cGQ8fPpSKmz17NgQCAQQCAZSUlGBqaoohQ4YgKioqxzbv3LmDrl27wsjICGpqajAzM0Pr1q1x4sQJiESiwuxigXjvuYje7WqjRxs32FoaYfmUrtBQV8XuE9dkxq/fdwmN3OwxsncT2FgYYuqw1qhsawqfA5clMV1a1sLEQS3g7mJbXN34aWt3+6FP+zro2bY27CyNsGJqN5RSV8XO47nkYe8lNK5tj1G9m8DWwhDTh7dGFTtTbDzgD0A8u7Buz0VMGOCJlu6V4WRtDO85ffDhUyxO+t8tzq4VCPMgtn7vJfRsWwfdW7vB1sIQSyd1gYaaKvb6XpcZv3G/Pxq62mFEz8awMTfE5CGt4Gxrgi2HrkhifmlWEw1cbGFmXA52lkaYM6oD4j9/RfCLd8XVrQLz6lAT28/cx+5zD/AkNBLjVp/Dl6QU9GrmJDO+lr0xbjx6h4OXHiM0PA4X77zGIf/HqGFjCABQV1VG27o2mL35Mq4+eItXYTFYsusqXr6PxoBWVYqzawWyft8l9GxTB91aZYyHieLxsCeX8eCTMR68vh0PNibYfPCKVFxYRAxmrDyENbN6Q1lZqTi68lPW7bmIXu3qoEdrN9haGGHZ5C7i94tc8rBhnz8audnj116Nxe8XQ1uhsq0JNmXkQVtTAwf/GoH2TarDyqw8ajpZYPGETrj7OBRvP+R8Hy1qclm0fE9SUhKaNGmCzZs3Y/78+Xj69ClOnTqF1NRUuLq64vp16V+Oo6MjwsLC8ObNG2zZsgVnzpzB8OHDpWKOHTsGNzc3JCQkYNu2bQgODsaZM2fQoUMHzJgxA7GxscXZRYnklFTcfRwK91pZxYVQKIS7iy0C74fIXOfm/ZAcxUhDNzvcvP+qKJtapJJTUhH0OBQe2fNQyxaBufQr4P4reLjYSS1r5GYvydvrd5H4GBkHj1pZMTqaGqjhaI7AeyGF3ofCwDyIJaek4t6TUDSoaSNZJhQKUd/FBjcfhMhc59aDV2iQbb/wcLXLNT45JRU7jl2FtqYGHKyMC6vphUpFWYiqVuVxKei1ZJlIBPgHvYGLXQWZ6wQEv0NVq/KonlGkmBnqoGlNC5wLFI8fZSUBlJWE+JqcKrXe1+RUuDnI5ynkzPFQ3yXbeKhpg1u5/H5vPnyF+jVzjodbD7Pi09PTMXLuTgzv0Qi2lkZF0fRClZySirtPQqWO/0KhEA1cbHM9/t98EIIG3+QNABq62ef5fhGX8BUCgQA6WhqF0/ACUMhrWv744w9cu3YNd+7cQZUq4srfzMwMhw4dgqurKwYOHIgHDx5AIBAAAJSVlWFoKN5BjY2N0blzZ2zZskWyvc+fP2PgwIFo1aoVDh8+LPVa9vb2GDhwYInNtETGfEZaWjr0dbWlluvrauHZ648y1wmPjIO+rpbUMgNdLYRHyp4eVASRMQkZeZDul76uNp6F5JEHvezxWgiPjAMAfMz4N3uMgV5WjLxhHsSiJPtFzn49fx0uc53wyHjol80WXzZnH8/+7wGGzdyGxK8pKK+njX1/DIdeGfk8LaKnrQFlJSEioj9LLY+I+QxrU12Z6xy89Bi62ho4/Xt3CASAirISNp8Mwor9NwAACYkpCHj0DhO718bT0EiEx3xBJ3c7uNhVwMuwmKLu0g/Jczy8kT0eIiLjZcZ/Ox5W77wAJSUhBnV2L/xGF4Hc8mBQVgvP8zg+GGR/fymb+/vF16QUzF1zDL80rQ6t0sVftCjkTMvu3bvRtGlTScGSSSgUYuzYsXj06BHu3pU9rR0SEoK///4bqqqqkmVnz55FZGQkJk2alOtrZhZA2SUlJSEuLk7qQUSKq251a1zYNgm+68egoZsdhvy2NdfrARRRXWdTjOvihglrz8Nj1A70mncUzVwsMaG7myRm6LJTEAiA4J3D8fHYWAxpWx2H/B8jPb3kTpMXt7uPQ+FzwB+rpvfM9fj/X5OSmoZB07dAJAJ+n9ylRNqgkEXL06dPYW9vL/O5zOVPnz6VLLt//z40NTWhoaEBCwsLPHz4EJMnT5baHgDY2mZNqQUGBkJTU1Py8PX1lfl6ixYtgo6OjuRhamr60/37ll6Z0lBSEiIiSroYioiKz1EdZzLQ085xkA2PiodBtk/SikSvjGZGHqT7FREVBwO9PPIQmT0+XhJfPuPf7DHhkfG5brOkMQ9iupL9Qka/dGWPcwM9LURkuygzIjpnH0trqMHCRB81nMyxcloPKCsJc70uoqRFxiUiNS0d+mVLSy3XL1Ma4VGfZa4zvXdd7Pd7hB1/38ejkE84ee055m27grGdXZH53hzyIRatJ++DcYdVcOqzHk3G7oKyshCvP5TMafLv+ZHxoK+nJTs+YzzcuPsCn6ITULPjbJg0GAuTBmPx9kMU5qw+CpeOc4qmIz8ptzyER+d+/DfQ00Z49vcXGfGZBcvbD1E4+NeIEpllAeS8aNm1a5dU4XDlStYFUgU5XWNra4ugoCAEBgZi8uTJ8PT0xMiRI/Ncp3LlyggKCkJQUBA+f/6M1NRUmXFTp05FbGys5BEaGprvduWHqooyqtiZ4nJgVhGWnp6Oy4FP4eJsLnOdms7muHzzqdQy/4AnqOlsUahtK06qKsqoamcK/8AnkmVZeZDdr1rOFlLxAHDxxmNJ3syM9VBeT1sqJi4hEbcehsClsnmh96EwMA9iqirKqGxriiu3pPeLf24+RU0nc5nr1HCywJVs+8XlgCe5xmdtV4SkZNn7f0lLSU1H0POPcK9SUbJMIAAaVK2IwMc574IBAA01ZaRnO36mZcygZJ9R+JKUgo/Rn6GjqYbG1c1x6vrzQu5B4cgcD//czDYebj1FjVx+vzUdLfDPrWzjIfCJ5KsDOjV3gd/2STi/daLkYVhOB149GmHPimFF1ZWfoqqijCq2Od8vrgTmfvyv6WSOK4HZ3y8eS8VnFiwvQyNw8K8R0NUpnX0zxUaui5a2bdtKCoegoCDUrFkTAGBjY4Pg4GCZ62Qut7HJurBIVVUVVlZWcHJywuLFi6GkpIQ5c7IqZWtrawDAkydZB201NTVYWVnBysoqzzaqqalBW1tb6lHYhndviB3HrmLvyRt4+uoDJizZjy9fk9C9tXg612v2dsxbc1wSP7SrB/yuPcKaXRfwLOQDlmw8haDgNxjUuYEkJjr2M+4/fYsnr8Tfu/D89Ufcf/pWcn2DPPLq0Qjbj17FHt/rePLqA8Yt3ofPiUno2Uach2GztmPO6mOS+KHdPHDh2iOs3nkBT0M+YPGGkwgKfoPBGeenBQIBhnVviGWbz+CU/z08fP4Ow2fvgGE5HbRyl9+7JJgHsaHdPLDr+DXsOxWApyEfMPn3A/jyNRndWrsCAH6duxMLvE9I4gd3ccfF68Hw3u2HZyEf8bvPadx9HIr+HcW3+n5OTMLCdSdw60EIQsOicPdxKMYs2I0Pn2LRplHVkuhivqw9chN9mldGt8aOsDHVxYoRTVFaTQW7zj0AAHiPb4GZ39zOfCbgJfq3qoJfGtiiYnkdeFQzw7TedXEm4IXk9E+j6uZoXMNc8vyJRV3x9G2UZJvyaGhXD+w6cQ37M8fDsozx0Eo8HkbOkx4PgzLGw7o9fnj2+iOWbRKPhwGdxLnS1SkNO8sKUg9lZSXo62rDyqx8ifQxP4Z1b4idx7PeLyYu3Y8vX5PRPSMPI+bswLy1We8XQ7q6w+96MNbuEu8XSzeeQlBwKAZm5CElNQ0Dpm5CUPAbeM/pg7R0ET5GxuFjZBySU4q/mJfrC3G1tLSgpZVzSqtbt26YPn067t69K3VdS3p6OlauXAkHB4cc17t8a8aMGWjUqBGGDx+OChUqoFmzZtDV1cWSJUtw5MiRIunLz+jQtAYiYxKweMNJhEfGw8nGGPv/8JJMY779GA2hMOsTUq3Kllg/rx8WrvPFAm9fWJrqY/vSwbCvlHU3wZkr9zFy3i7Jz4NnbAUATBzUApMHtyyejhXQL81q4FNMAhauF+fB2cYYB/8ckZWHD1EQfvNJ0bWKJTbO74cF3r6Yt/YELE31sXPZEDhYZeVhdJ8m+JKYhLEL9yA2IRFuVSrh4J9eUFdTKfb+5RfzINa+SXVExiRg6cZTiIiKg6O1CfasGCa5aP1dtv3CxdkCa+f0wZINp7BovS8sTPSxZfFAyX6hJBTi+etw7D+1GVGxCSirUxpV7Sri6NpRsJPjO0eOXH6CctqlMK13XRiULYX7LyPQaeZBRMR8AQCY6GtLXYuybM81iEQiTO9TD0Z6moiMTcSZgBeYt+0fSYx2aTXM7FcfFcppIjr+K0787xnmb7uC1LT0Yu9ffrXLHA8+WeNh9/Js40GQbTzMzjYeFg2EnaXsu64URYem4jws2Xgq48snTbBv5fBvjg/RUjNqtSpbYt3cvli0/iQWrDsBS1MDbFs6SLJfhIXH4MwVcbHasPcSqdc6umYk6tawLqaeiQlEJfkFJLno168fYmJicPToUZnPf/36FR4eHnj//j2WL18OV1dXfPz4EQsXLsS5c+dw/vx5uLmJP3XOnj0bR48eRVBQkNQ2XF1d4eLigtWrVwMAjhw5gq5du6Jp06YYNWoUrK2tkZCQgDNnzmDy5Mk4fvw42rRp8922x8XFQUdHB+8jYopk1kWRKAl58Rplyfy21f86w3YrS7oJciHs6NiSboLcUFb6bx8r4+LiYGxQFrGxsd9935Tr00O5UVdXh5+fH/r06YNp06bBysoKzZs3h5KSEq5fvy4pWPIyduxY+Pj4SK5B6dChA65evYpSpUqhT58+sLW1RaNGjeDn54e9e/eidevWRd0tIiIiyoNczrQoMs60ZOFMC32LMy1inGkR40xLFs60/MtnWoiIiOi/h0ULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQTlkm7Av5WSUAAloaCkm0FyQCQSlXQT5IJQwP0BAN4eGVPSTZALRm2WlnQT5Eb4yckl3YQSVZBDJGdaiIiISCGwaCEiIiKFwKKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFwKKFiIiIFAKLFiIiIlIILFqIiIhIIbBoISIiIoXAooWIiIgUAosWIiIiUggsWoiIiEghsGghIiIihcCihYiIiBQCixYiIiJSCCxaiIiISCGwaCEiIiKFoFzSDaD82bjfH3/tvIDwyDg4WRtjycTOqOFonmv80fO3sXDdSbwJi4SlqT5mj2yPZnUdJc+LRCIsWn8S249eRWxCIlwrW2L5lK6oVNGgGHrz45gHMZ8DlyV5cLQ2xpIJnb6ThztYtN4Xb8KixHn4tR2aZs/DhlPYIcmDBZZNlv88bDp4GWt3+SE8Kg6OVsZYOK4Tqjua5Rp//MIdLN5wEqEfomBpoo/fRrRFkzriPKSkpmHRel9cuPoIr99HQktTHQ1q2uI3r7Yw1Ncpri79kK2HrmDdHj9ERMXDvlIFzBvbEdUccs+Dr18Qfvc5hbcfomBuoo9pw9ugcW0HyfNjF+zCgdOBUuu417LDrhXDiqwPhWFQm+oY2ckVBrqaePAyHJPXnsXtJ2EyY5WVhBjbrTa6N3GGUTktPH8bidmbLuHCzZc/vE158W/eLzjTogAOn72FGX8cweRBLXBpx2Q4WRuj48g1iIiKlxl/4+5LDJqxFb3a1Yb/zilo5V4FvSZswKPn7yUxq7afx/p9/lgxtRvObZmAUhqq6DhyDb4mpRRXtwqMeRA7fE6ch0mDWuDi9klwsjZGp1Frc8/DvZcY/NtW9GxbG5d2TEZL98roNXEjHr3IysOf289jwz5/LJ/SFec2j0cpDTV0GrVWrvNw9PxtzPrzCCYMbI7zWyfC0doYXcfmnoeAey8xdNY29GhTGxe2TUKLBpXRd7IPgjPykPg1GfeevMW4/p44v3UitiwaiBdvwtF70obi7FaBHb9wG3NXH8XY/s1xetMEOFgZo9e4dfgULTsPN++/wog529GttRvObJ6A5vWdMWjqJjx+Kf1G7OFqh9vH5koea2b3KY7u/LAO7vaYP6Qxluz6Bx4jNuPBy484tKAryumUkhk/o18D9GtZDZPXnoPb4I3YcvIOdsz8Bc6Vyv/wNuXBv32/kKuipV+/fhAIBJKHnp4emjdvjnv37uW6TkhICAQCAYKCgnKNuXr1Klq2bImyZctCXV0dzs7OWLFiBdLS0nLEXrx4ES1btoSenh5KlSoFBwcHjB8/Hu/evSuMLv6Qtbv90Kd9HfRsWxt2lkZYMbUbSqmrYufxazLj1++9hMa17TGqdxPYWhhi+vDWqGJnio0H/AGIP1Wv23MREwZ4oqV7ZThZG8N7Th98+BSLk/53i7NrBcI8iK3dfRF92tdGzzZu4jxM6YpS6qrYdSKPPLh9k4dhrVHZzhQ++y8DyMjD3ksYn5EHR2tjeM/unZGH3Pe9krZuz0X0alsH3Vu7wdbCCL9P6gINNVXs8b0uM37jfn80crXHr70aw8bcEFOGtkJlWxNsOngFAKCtqYGDf45AuybVYWVWHjWdLLBofCfcfRyKtx+iirNrBbJh7yV0b1MbXVu5wsbCEIsndoa6uir2+t6QGb/pgD88XO0wvEcjWJsbYuLglnCyMcHWQ1ek4tRUlWGgpy15lNGW3zdqAPD6pRa2n7mL3Wfv48mbSIz78wy+JKWil2dlmfFdGjth5d6rOBf4Aq8/xGCz7x2cC3yBXzvW+uFtyoN/+34hV0ULADRv3hxhYWEICwvDhQsXoKysjNatW//w9o4cOQJ3d3eYmJjg4sWLePz4MUaPHo358+ejW7duEIlEktj169ejSZMmMDQ0xKFDh/Do0SOsW7cOsbGxWL58eWF0r8CSU1IR9DgUHrVsJcuEQiHca9ki8P4rmesE3H8FDxc7qWWN3OwReD8EAPD6XSQ+RsbBo1ZWjI6mBmo4miPwXkih96EwMA9iySmpuPs4FO4u2fLgYivpV3aB90Pg/k3eAKCRm50kb6/fZ+YhK0Y7Mw+55LakJaek4u6TUDTIlocGLra4+UB2m28+CEEDFxupZR6u9rnGA0BcwlcIBALoaGkUTsMLWXJKKu4/fYv6NbP6JRQKUb+mDW4/DJG5zq0HIVLxAODuaodbD6Tjr915jiqtZ6BB9wWYumw/omM/F3bzC42KshBVrQ1x6XbW71IkAvzvhMDFwVjmOmoqyvianCq17GtSKtwcTX54myXtv7BfyN01LWpqajA0NAQAGBoaYsqUKahfvz4iIiKgr69foG19/vwZgwcPRtu2bbFhQ9ZU1qBBg1C+fHm0bdsW+/fvR9euXfH27VuMGjUKo0aNwsqVKyWx5ubmaNCgAWJiYgqlfwUVGZOAtLR06OtqSS3X19XGs5CPMtcJj4yDvl72eC2ER8YBAD5m/Js9xkAvK0beMA9ikTGfM/KgLbVcX1cLT1/nngeDbHkz0NVCeMZ0sSQPOXIrv3mIkuQhZ5uf55EHWXkLj5Q9bf41KQXz1h5Dh6bVoVVaPouWqFjZeSiXRx4iouJRrmy2vJXVQkRU1u/aw9UeLdyrwNRIF6/ffcKSDSfRa8J6HF83BkpKcvdZF3rapaCsJEREzBep5RHRn2FtqidzHb9bL+HVsRau3g/Fq7BouFczR+u6tlASCn54myXtv7BfyF3R8q2EhATs3LkTVlZW0NMr+CA5e/YsIiMjMWHChBzPtWnTBjY2NtizZw+6du2KAwcOIDk5GZMmTZK5rTJlyshcnpSUhKSkJMnPcXHyeZAnovxLSU3D4BlbIBIBv0/qUtLNKXbtmlSX/N++UgXYV6qAul3n49qd56iXbZZGUU3xPodVY1oiwGcIRABevY/G7rP30FOOT/2UNHnYL+SuZPb19YWmpiY0NTWhpaWF48ePY9++fRAKC97Up0+fAgDs7e1lPm9nZyeJefbsGbS1tWFkZFSg11i0aBF0dHQkD1NT0wK3My96ZTShpCTMcRFVRFQcDPS0Za5joKeNiMjs8fGS+PIZ/2aPCY+Mz3WbJY15ENMrUzojD9LFcURUvKQ/2RnoaUtmVTKFR8VLZl8keciRW/nNg64kD7LarCVzHQM9bZl5yx6fkpqGQdO3IPRDFA78OUJuZ1kAQFdHdh4+5fG709fVynGRbkR0fI5P298yMy4H3TKlEfI24ucbXQQi474gNS0d+mWkr7vRL1sa4dEJsteJTUSvOYdg3G4ZKvdeg1qDNuDz12SEfIj54W2WtP/CfiF3RUvDhg0RFBSEoKAgBAQEwNPTEy1atMDr16/RokULSUHj6Oj4/Y1l+Pa6lbxiBAJBgds7depUxMbGSh6hoaEF3kZeVFWUUdXOFP6BTyTL0tPTcTnwKVycLWSuU8vZQioeAC7eeAwXZ3MAgJmxHsrraUvFxCUk4tbDELhUNi/U9hcW5kFMVUUZVexMcTnwqWRZeno6/G8+lfQrOxdnc6l4ALh044kkb2YV8shDLrktaaoqyqhia4orN6XzcOXmE9R0kt3mmk7mUvEA4B/wWCo+88D86m0EDv45Aro6pYumA4VEVUUZzjYm+OfWM8my9PR0/HPrKarncgt8DSdz/HPzmdSyK4FPUMNJdjwAvA+PQXTsFxiUk89bv1NS0xH07APcq5lLlgkEQIOqZgh8lPdNFEkpaQiLTICykhBt6tnh9LVnP73NkvJf2C/k7vRQ6dKlYWVlJfnZx8cHOjo62LhxI3x8fJCYmAgAUFFR+e62bGzE05jBwcGoU6dOjueDg4Ph4OAgiY2NjUVYWFiBZlvU1NSgpqaW7/gf4dWjEbzm7EA1+4qo7mgO7z0X8TkxCT3buAEAhs3aDiN9Hcz6tR0AYGg3D7Qe+gdW77yAZvUccfjsLQQFv8Ef07oDAAQCAYZ1b4hlm8/A0lQfZsZ6WLjuJAzL6aCVe5Ui7cvPYB7EvHo0xIg5O1HVviKqO5ph3d5L+JKYhB6txXkYPms7jAzKYOaItgDEeWgzdBVW77qAZnUdcfjsbQQFv8HKad0AZOShmweWb/4blUwNYFZBDwvX+WbkQX6nyod1b4iR83aiip0pqjuaYf3eS/jyNRndWrsCAEbM2QEjfR3M8BLnYXAXd7T3+hNrd/uhaR1HHDl/C3cfh2L5FHEeUlLTMHDaJtx78hY7lw1FWrpIcr1PWe1SUFWRu8MlAGBINw+MXbAbVexMUdW+Inz2+yMxMRldW4nzMHreThjq62DqsDYAgIGd3dHp17+wfs9FNK7jgGPnb+Pe41AsmdQVAPD5SxJWbDmDlu5VYKCnhdfvIrFg7XGYG5eDey27XNtR0tYeDsDaCa1x5+kH3H7yHsM7uKC0ugp2nRXfAec9sTXCPsVj7hbx3YM1bCvAqJwm7r8IR4Vympjcqz6EAmDV/uv53qY8+rfvF/K5F35DIBBAKBQiMTERxsYFu2K7WbNm0NXVxfLly3MULcePH8ezZ88wb948AECnTp0wZcoULF26VOpC3EwxMTG5XtdS1H5pVgOfYhKwcP1JhEfGw9nGGAf/HCGZ/n37IQrCb2aJXKtYYuP8fljg7Yt5a0/A0lQfO5cNgYNVBUnM6D5N8CUxCWMX7kFsQiLcqlTCwT+9oK72/WKwpDAPYr80rYHI6AQs2iDOg5ONMQ6s8srKw8doCIXf5KGyJTbM64eF63wxf62vOA+/D4ZDpaw8jOrTBJ+/Jn+TB0scWCXfeWjfpDoioxOw1OdUxpcNmmDvyuEwyDjN8S5bHmpVtsS6OX2xaMNJLFx3ApamBti2ZBDsM/IQFhGDM1ceAAAa9Vki9VpH1oxE3erWxdSzgmnbuDoiYz5jmc9pRETFwcHKGDuWD5VcjJk9DzWdLbB6Vh8s3XgSSzb4wsJEHz6LBsLOUvxhTagkwOMX73HwdCDiEhJRvpw2GrjYYeLgllBTld+3jCP+wSinUwrT+tSHQdnSuP8yHJ2m75dcSGuir4309KxZdzVVJUzv6w5zozL4nJiMc4EvMGzpCcR9Tsr3NuXRv32/EIjyc+6kmPTr1w8fP37Eli1bAADR0dFYvXo1vL294efnBw8PjxzrhISEwMLCAnv37oWtrfRtnY6Ojjh27Bi6deuGAQMG4Ndff4W2tjYuXLiAiRMnonHjxti/f7/ktNDatWvx66+/on///ujTpw/Mzc3x9u1bbN++HZqamvm67TkuLg46Ojr4GBkLbW35vB6Aipcc7WIlKjWNeQCA5LT0km6CXDBp+3tJN0FuhJ+cXNJNKFFxcXEwKV8WsbHff9+Uu7L5zJkzktMzWlpasLOzw4EDB2QWLN/q1q1bjmWhoaHo1KkTLl68iAULFqB+/fr4+vUrrK2tMX36dIwZM0bqOhYvLy/Y2Nhg2bJl6NChAxITE2Fubo7WrVtj3LhxhdpPIiIiKhi5mmn5N+BMC2XHXUyMMy1inGkR40xLFs605H+mRe7uHiIiIiKShUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQTlkm7Av5VIJIJIJCrpZpAcEAgEJd0EuaDEj0gAgFJKSiXdBLkQdWZKSTdBbujWGlnSTShRorTkfMfyMEJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQQWLURERKQQWLQQERGRQmDRQkRERAqBRQsREREpBBYtREREpBBYtBAREZFCYNFCRERECoFFCxERESkEFi1ERESkEFi0EBERkUJg0UJEREQKgUULERERKQTlkm4A5Y/Pgcv4a+cFhEfGwdHaGEsmdEINR/Nc44+ev4NF633xJiwKlqb6mP1rOzSt6yh5XiQSYdGGU9hx9CpiExLhWtkCyyZ3RaWKBsXQmx/HPIht3O8vyYOTtTGWTOz8nTzcxsJ1J/EmLFKch5Ht0Sx7HtafxHZJHiyxfIr858HnwGWs3pU1HhaPz3s8HLtwBwvX+yI0YzzMGiE9Hk5cDMLWw//D3cdvEB33BZd2TIazjUkx9OTnFPZ+ceJiELYc/h/uBovz4L/zv5kHRT0+DOrcACN7NYaBnjYePHuHyb8fwO1Hr2XGKisJMbZ/M3Rv5Qoj/TJ4/vojZq8+hgvXgiUxd4/NQcUKejnW9TlwGROX7i+yfsjCmRYFcPjcLcz44wgmDWqBi9snwcnaGJ1GrUVEVLzM+Bv3XmLwb1vRs21tXNoxGS3dK6PXxI149OK9JObP7eexYZ8/lk/pinObx6OUhho6jVqLr0kpxdWtAmMexA6fFedh8qAWuLRjMpysjdFx5Jrc83D3JQbN2Ipe7WrDf+cUtHKvgl4TNuDR86w8rNp+Huv3+WPF1G44t2UCSmmoouPINXKdhyPnbuG3VUcwcWAL+G2bBCcrY3Qenft4CMgYD73a1MbF7ZPRskFl9J60EcHfjIcviclwq2KJWb+2K65u/LSi2C+YBzFFPD50aFod88d0wBKf0/DovQQPnr3Dob9GoFxZTZnxM4a3Qb8O9TD59wNw6zofWw7/gx1LB0sVqY36/g7b5lMlj/Yj/gIgLvqKm9wXLf369UP79u1zfd7DwwNjxozJ9fmoqCiMGTMGZmZmUFVVRYUKFTBgwAC8efMmR+yHDx8wcuRIWFpaQk1NDaampmjTpg0uXLhQCD35cWt3X0Sf9rXRs40b7CyNsGJKV5RSV8WuE9dkxq/fewmN3ewxqncT2FoYYvqw1qhsZwqf/ZcBiD89rNt7CeMHeKKle2U4WhvDe3ZvfPgUi5P+94qzawXCPIit3e2HPu3roGfb2uI8TO2GUuqq2Hk8jzzU/iYPw1ujip0pNh7wB5CRhz0XMSEjD07WxvCe0ycjD3eLs2sFsnbPRfRulzUelk/pCo28xsM+8XgYmZGHacNao7KtKXwOXJbEdG1ZCxMHtYC7i21xdeOnFfZ+AYjzMGlQC3jU+u/mQVGPD149GmH70avYfeI6nrz6gHGL9uLL12T0altbZnyXlrWwcutZnLv6CK/fRWLzoX9w7uoj/NqrkSQmMiYB4ZHxkodnPSe8DI3A/24/K65uSch90fIzoqKi4ObmhvPnz2PdunV4/vw59u7di+fPn8PFxQUvX76UxIaEhKBGjRrw8/PD77//jvv37+PMmTNo2LAhRowYUWJ9SE5Jxd3HoVIHUaFQCHcXWwTeD5G5TuD9ELhnO9g0crND4P1XAIDX7yPxMTJO6oCkramBGo7mkhh5wzyIJaekIuhxqFSbhUIh3GvZ5trmgPuv4OFiJ7WskZu9JG+v32XmIStGJzMP90IKvQ+FQTIesufhe+PBJffxoIiKYr9QRDw+iKkoK6GqnSkuBTyRLBOJRPAPeAIXZwuZ66ipKOeYOfqalAy3KpVyfY0uLVywK5cPSUXtX31Ny/Tp0/H+/Xs8f/4choaGAICKFSvi77//hrW1NUaMGIHTp08DALy8vCAQCBAQEIDSpUtLtuHo6IgBAwaUSPsBIDLmM9LS0qGvqy21XF9XC09ff5S5TnhkHAx0taSWGehqITxjmvRjZJxkG9m3GZ7xnLxhHsQiYxIy8pC9zdp4FpJ7HvT1cu+jJA/ZYgz05DkP4vFgkG08GOhq4Vke40H271r26QNFUBT7hSLi8UFMr4wmlJWVcpwSi4iKg7V5eZnr+F0PhlfPRrh65zlevf0EdxdbtG5YFUpCgcz4Vh6VoaOpgd2+Nwq9/fnxr51pSU9Px969e9GzZ09JwZJJQ0MDXl5e+PvvvxEVFYWoqCicOXMGI0aMkCpYMpUpUybX10lKSkJcXJzUg4iISBFMWX4QL9+EI+DAbwi/+geWTuqM3SeuIz1dJDO+V9s6OH/tET58ii3mlor9a4uWiIgIxMTEwN7eXubz9vb2EIlEeP78OZ4/fw6RSAQ7OzuZsXlZtGgRdHR0JA9TU9OfbboUvTKloaQkRESUdDEUERWP8nraMtcx0NPO8akpPCpe8qkic72c1Xg8DHLZZkljHsT0ymhm5CHnJ6nc2mygp42IyNz7KMlDtpjwSHnOg3g8hGcbD+Lfbx55kPm71pIZrwiKYr9QRDw+iEXGJCA1NU3mTGxus0ORMQnoNXEjjBuMQ+W2M1Gr0zx8/pKEkPeROWJNDcvCo5Ytth+9WiTtzw+FKVp27doFTU1NyePKlSv5Wk8kkl0tFjQmN1OnTkVsbKzkERoa+sPbkkVVRRlV7ExxOfCpZFl6ejr8bz6Fi7O5zHVcnM2l4gHg0o2sc5pmFfRQXk8b/oFZ5z3jEhJx62FIruc9SxrzIKaqooyqdqZSbU5PT8flwKe5trmWs4VUPABcvPFYkjcz4zzyUNm80PtQGHIbD+I8mMtcx8XZHJdvZhsPeZzrVwRFsV8oIh4fxFJS0xCU7doegUCABi42370OJyk5FWERsVBWEqJNo6o4LeNi4x5taiMiOh5n//ew0NueXwpzTUvbtm3h6uoq+dnY2DjPeH19fZQpUwbBwcEynw8ODoZAIICVlRUA8S/28ePHBW6Xmpoa1NTUCrxeQXj1aIgRc3aiqn1FVHc0w7q9l/AlMQk9WrsBAIbP2g4jgzKYOaItAGBoNw+0GboKq3ddQLO6jjh89jaCgt9g5bRuAMR9HdbNA8s3/41KpgYwq6CHhet8YVhOB63cKxdpX34G8yDm1aMRvObsQDX7iqjuaA7vPRfxOTEJPduI8zBs1nYY6etIblcd2s0DrYf+gdU7L6BZPUccPnsLQcFv8Me07gAy8tC9IZZtPgNLU32YGeth4bqTGXmoUmL9/B6v7g0xYm7GeHAww/q9l/Dl6zfjYfZ2GOl/Mx66eqDNsFVYs+sCmtZ1xJFzGeNhajfJNqNjP+Ptx2h8iBBPfT/PuB7CQE8710/sJa2w9wsgZx4yrxMy0NVG+XL/jTwo6vFh7W4/rJ3VG3eC3+D2wxAM794QpTXUsOvEdQCA9+zeCIuIxdw1xwEANRzNYGRQBvefvkUF/TKYPKQlhEIBVm0/L7VdgUCAnm3csPfkDaSlpRd7vzIpTNGipaUFLa38T18KhUJ06dIFu3btwty5c6Wua0lMTMTatWvh6ekJXV1dAICnpyfWrFmDUaNG5biuJSYmJs/rWoraL01rIDI6AYs2nER4ZDycbIxxYJWXZIry7cdoCL+5aMq1siU2zOuHhet8MX+tLyxN9bHz98FwqFRBEjOqTxN8/pqMsQv3IDYhEW5VLHFglRfU1VSKvX/5xTyI/dKsBj7FJGDhenEenG2M/9/enUc1eeX/A3+HJSGQgASRzRRFZLOI1gVpzxlkjhigRatS1NIpjErrUkTcaOsubmNr+cqMCgcQbKtC1XFDhaK1ymi1dmqUSkQQEVrD1BZF4wJC7u+P/PKUGHYRiP28zsk55rn3uc/9XG+efHLzPAR7k+b8MQ5V1TDiNRoHHxekronC2m05SNh6WDMOn74HL9c/xiH23TF4+Ki20TgMwN6knj0OEwI147Ch0Xz46v/+mA+/PDUfRv7/+bA2OQdrtmnmwxcbo+HZaD4cKyhETMJO7vmMpZkAgMUzghEfHdI1gbXT83hdHCsoxAerG43DkkwAmnH48L0/zzgY4vlhf/6P6N1LhI/ffx19bMQovPYLwub+8Xec+tpLoG707YJAYIolM99AP6feePCoFvlnrmDm8s9xT/VIp93RI90hdZDgy0PnujSep/HYs3w30gWioqJw9+5dHDhwoMny0aNHw8nJCYsWLdLZ7uDgABMTE/j6+kIoFGLjxo14+eWXcePGDSxduhTFxcX47rvv4OLiAgAoKyvDa6+9BolEgtWrV2Pw4MGor69Hfn4+tm3b1uyKzdPu3bsHKysrVP12F5aWPfMTCelaPF7TV+H/2TR3Yd+fDU0H8jTJyJju7kK3Yg11qC1MRU1NTavvmwZzTUtLdu3ahaFDh+o8UlNTYWNjg3PnziEgIADvv/8+BgwYgPDwcAwYMAAXLlzgEhYAcHFxwY8//oiAgAAsWLAAL7/8MgIDA3HixAls27atG6MjhBBCCGAAKy2GhlZayNNopUWDVlo0aDqQp9FKy59spYUQQgghLz5KWgghhBBiEChpIYQQQohBoKSFEEIIIQaBkhZCCCGEGARKWgghhBBiEChpIYQQQohBoKSFEEIIIQaBkhZCCCGEGARKWgghhBBiEChpIYQQQohBoKSFEEIIIQaBkhZCCCGEGARKWgghhBBiEChpIYQQQohBoKSFEEIIIQaBkhZCCCGEGARKWgghhBBiEChpIYQQQohBoKSFEEIIIQaBkhZCCCGEGARKWgghhBBiEChpIYQQQohBoKSFEEIIIQaBkhZCCCGEGAST7u7Ai4YxBgC4f/9eN/eE9BQ8Hq+7u9AjqNWsu7vQI9B0IE9jDXXd3YVupY1f+/7ZEkpaOtn9+/cBAAP7v9TNPSGEEEIMx/3792FlZdViHR5rS2pD2kytVuPWrVsQi8Xd9gn73r17kEqlqKyshKWlZbf0oSegcdCgcdCgcdCgcdCgcdDoCePAGMP9+/fh6OgII6OWr1qhlZZOZmRkhL59+3Z3NwAAlpaWf+oXoxaNgwaNgwaNgwaNgwaNg0Z3j0NrKyxadCEuIYQQQgwCJS2EEEIIMQiUtLyABAIBVqxYAYFA0N1d6VY0Dho0Dho0Dho0Dho0DhqGNg50IS4hhBBCDAKttBBCCCHEIFDSQgghhBCDQEkLIYQQQgwCJS2EEEIIMQiUtLxgKisrMW3aNDg6OoLP58PZ2RmxsbH4/fffu7trbRYVFQUej8c9bGxsEBQUhMuXLze7T3l5ud4+Y8eOxcWLF7k6o0eP1qmjfcycOZOr03i7paUlRowYgYMHDz7XeNsiKioKb775ZrPljWMzMzODl5cXtm7dypVnZmY2GbuZmZnOMbTbTU1N0b9/fyxevBiPHz9+nqE1qyPzQOvKlSsIDw+Hra0tBAIB3NzcsHz5cjx8+FCnXr9+/bj2zc3N4e3tjbS0NL32GGNITU2Fn58fLC0tIRKJMGjQIMTGxqK0tLTTYm5Na/MAAB49eoQVK1bAzc0NAoEAvXv3xltvvYUrV67o1Fu5ciUXu7GxMaRSKd577z1UV1frtXnx4kVMnjwZDg4OEAgEcHZ2xhtvvIHDhw+36fdiOtOznB/kcnmzdc6ePYuQkBBYW1vDzMwM3t7e+Oyzz9DQ0KBX9+TJkwgJCYGNjQ3Mzc3h5eWFBQsW4JdffumMENulLeeGefPmNVteXV2NefPmwdnZGXw+H46Ojpg2bRoqKir06lZVVSEmJgYuLi4QCASQSqUIDQ3FiRMnOiGStqGk5QVSVlaG4cOHo6SkBLt370ZpaSmSk5Nx4sQJ+Pn5NXky6qmCgoKgVCqhVCpx4sQJmJiY4I033mh1v+PHj0OpVCIvLw8qlQrBwcG4e/cuVx4dHc21q31s3LhRp42MjAwolUr88MMPeO211xAWFobCwsLODrHTaWMrKipCeHg45syZg927d3PllpaWerHfvHlTpw3tuJeVlSExMREpKSlYsWJFV4ei15/2zINz587B19cXdXV1OHLkCK5du4a1a9ciMzMTgYGBqKvT/XG61atXQ6lU4qeffsI777yD6OhoHDt2jCtnjOHtt9/G3LlzERISgq+//hpFRUVIT0+HmZkZ1qxZ81xi74ja2lqMGTMG27dvx5o1a3Dt2jUcPXoU9fX18PX1xblz53TqDxo0CEqlEhUVFcjIyEBubi5mzZqlU+fgwYMYNWoUVCoVduzYAYVCgdzcXEyYMAFLly5FTU1NV4YIoOPnh+bs378f/v7+6Nu3L06ePImrV68iNjYWa9aswZQpU3QSs5SUFIwZMwb29vbYt28fioqKkJycjJqaGmzatKkzwusy1dXVGDVqFI4fP47k5GSUlpYiKysLpaWlGDFiBMrKyri65eXlGDZsGL755ht88sknKCwsRG5uLgICAjBnzpyu6zQjL4ygoCDWt29f9vDhQ53tSqWSmZubs5kzZ3ZTz9onMjKSjR8/XmdbQUEBA8B+/fXXJve5ceMGA8AuXrzIbTtz5gwDwHJzcxljjPn7+7PY2NgWjw2A7d+/n3t+7949BoBt3ry5I6F0mqbGpLGmYhs4cCCbMmUKY4yxjIwMZmVl1e5jTJw4kQ0dOrQDPX52HZkHarWaeXl5seHDh7OGhgadMrlczng8HtuwYQO3zdnZmSUmJurUk0gkLC4ujnu+e/duBoAdPHiw2WN2ldbmwYYNGxiPx2NyuVxne0NDAxs+fDjz8vLi+rtixQrm4+OjU2/+/PnM2tqae65SqZiNjQ2bMGFCs8fsyvgZ67zzg5Y2xokTJ+qVHTp0iAFgWVlZjDHGKisrGZ/PZ/PmzWvyOHfu3GlXLJ2hI+cGrZkzZzILCwumVCp1tj98+JA5OTmxoKAgbltwcDBzcnJiKpVKr52ujJtWWl4Q1dXVyMvLw+zZsyEUCnXK7O3tERERgezs7C5fyu0MKpUKX375JVxdXWFjY9Pm/bTj8PQn67aqr69Heno6AIDP53eoje4kFAo7HDsA/PTTTzh79myPib0t80Aul6OoqAjz58/X++E1Hx8fjBkzRmf1qTG1Wo19+/bhzp07OjHv3r0b7u7uGDduXJP7ddcPozZl165dCAwMhI+Pj852IyMjxMXFoaioCJcuXWpy3/LycuTl5enE/vXXX+P333/H4sWLmz1md8ff0fODljbGhQsX6pWFhobCzc2NmzN79uxBXV1ds+PRq1evdh+/u6jVamRlZSEiIgL29vY6ZUKhELNnz0ZeXh6qq6tRXV2N3NxczJkzBxYWFnptdWXclLS8IEpKSsAYg6enZ5Plnp6euHPnDm7fvt3FPeuYnJwciEQiiEQiiMViHDp0CNnZ2a3+AqjW3bt3kZCQAJFIhJEjR3Lbt27dyrWrfezcuVNn36lTp0IkEkEgECAuLg79+vVDeHh4p8b3PDU0NODLL7/E5cuX8de//pXbXlNToxd7cHCwzr7acdd+p//rr79i0aJFXR2CXn/aOg+uXbsGAC2+DrR1tOLj47n/77CwMFhbW2PGjBk6bbq7u+vsM2/ePK5fPeUHUgFNX1uKXVtHq7CwECKRCEKhEP3798eVK1cQHx+v0x4AnfgvXLigM4dycnKeRygtetbzQ2OtzRkPDw+uTklJCSwtLeHg4NDxzvcQt2/fxt27d1ucL4wxlJaWorS0FIwxeHh4dHEv9VHS8oIxxJWUpgQEBEAul0Mul+P777+HTCZDcHAwbt68ieDgYO6ENWjQIJ39Xn31VYhEIlhbW+PSpUvIzs6GnZ0dVx4REcG1q308/Qk6MTERcrkcx44dg5eXF9LS0iCRSLok7tbs3LlT5w2joKCAK9MmZEKhENHR0YiLi9O5PkEsFuvF/vRFp9pxP3/+PCIjI/H3v/8dkyZN6rL4ntbRedCe18GiRYsgl8vxzTffwNfXF4mJiXB1dW1xnyVLlkAul2P58uVQqVQdiu1ZtDQP2hO7u7s75HI5Lly4gPj4eMhkMsTExLS4z+DBg7n/kwcPHqC+vr7DcXRUR+dFS9oyboyxbl9Zak5Lc6IlbY27pzDp7g6QzuHq6goejweFQoEJEybolSsUClhbW8PW1rYbetd+FhYWOm8caWlpsLKyQmpqKtLS0vDo0SMAgKmpqc5+2dnZ8PLygo2NTZNLllZWVq2+Idnb28PV1RWurq7IyMhASEgIioqK0KdPn2cP7BmNGzcOvr6+3HMnJyfu3xEREViyZAmEQiEcHBz0PnUaGRm1Gnvjcd++fTt8fHyQnp6O6dOnd2IUbdfeeeDm5gZAM9+HDh2q155CoeDqaPXu3Zv7/96zZw+8vb0xfPhweHl5AQAGDhyI4uJinX1sbW1ha2vbbXOiuXng5uYGhULR5D7a7Y3j5/P53Phu2LABr7/+OlatWoWEhAQAmtgBoLi4GKNGjQKg+a2a1ubR89bR80NTGs+ZV199Va9coVBwc8HNzQ01NTVQKpU9brWlpXNDU2xtbdGrV68W5wuPx+PGmcfj4erVq53X4Q6ilZYXhI2NDQIDA7F161buBatVVVWFnTt3YvLkyT32U0JreDwejIyM8OjRIzg5OXFvMs7Ozjr1pFIpBgwY0GnfsY4cORLDhg3D2rVrO6W9ZyUWi7nYXV1dda5f0iZkTk5OHVomf5qRkRE+/vhjLF26VG9OdZfW5sGQIUPg4eGBxMREqNVqnX0vXbqE48ePY+rUqc22L5VKMXnyZHz00UfctqlTp6K4uLhH3Pqu1dw8mDJlCo4fP6533YparUZiYiK8vLz0rndpbOnSpfj0009x69YtAMDYsWMhkUjwj3/84/kF0wnaen5oijbGpu78OXToEEpKSrg5ExYWBj6fr3fHoVbjOxW7WkvnhqYYGRkhPDwcu3btQlVVlU7Zo0ePsHXrVshkMkgkEkgkEshkMmzZsgUPHjzQa6sr46ak5QXyr3/9C7W1tZDJZDh9+jQqKyuRm5uLwMBAODk59Zg33raora1FVVUVqqqqoFAoEBMTA5VKhdDQ0Gdq9+HDh1y72sedO3da3GfevHlISUnplr/B0JkYY3qxV1VV6b25N/bWW2/B2NgYW7Zs6cKe/qG984DH4yE9PR1FRUWYNGkSvv/+e1RUVGDPnj0IDQ2Fn59fi3+zAgBiY2Nx+PBh/PDDDwA0iUBYWBimTJmC1atX4/z58ygvL8epU6eQnZ0NY2Pjzg67w+Li4jBy5EiEhoZiz549qKiowIULFzBp0iQoFAqkp6e3+MHFz88PgwcPxrp16wAAIpEIaWlpOHLkCF5//XXk5eWhrKwMly9f5t64uyP+jp4fiouL9b4i5fP5SElJwcGDB/Hee+/h8uXLKC8vR3p6OqKiohAWFsZd0yaVSpGYmIjNmzdj+vTpOHXqFG7evIkzZ87g/fff51aoeprbt2/rxf2///0P69atg729PQIDA3Hs2DFUVlbi9OnTkMlkePLkic7rfsuWLWhoaMDIkSOxb98+lJSUQKFQICkpCX5+fl0XTJfdp0S6RHl5OYuMjGR2dnbM1NSUSaVSFhMTw3777bfu7lqbRUZGMgDcQywWsxEjRrC9e/c2u09LtzRq+fv767SrfchkMq4OnrrlmTHNLZ0eHh5s1qxZzxpahz3LbY2MaW55bip2ANztjs0dY/369czW1rbJWx2fp47MA63Lly+zSZMmMYlEwkxNTdmAAQPY0qVL2YMHD3TqNXXLM2OMyWQyFhwczD1vaGhgycnJzNfXl1lYWDA+n89cXFxYdHQ0KyoqeuZY26q1ecAYYw8ePGBLlixhrq6uzNTUlEkkEjZp0iRWWFioU6+pW54Z09ziLRAIWEVFBbftwoULLCwsjPXp04eZmJgwGxsbJpPJWFZWVrfc8tzR80NTj8rKSsYYY6dPn2YymYxZWloyPp/PBg0axD799FNWX1+v115+fj6TyWTM2tqamZmZMQ8PD7Zw4UJ269at5xZ3c9pybmgq7oSEBMYYY7dv32YxMTFMKpUyU1NTZmdnx6KiotjNmzf12rp16xabM2cOc3Z2Znw+nzk5ObFx48axkydPPqfo9PEY60FX2BBCCCGENIO+HiKEEEKIQaCkhRBCCCEGgZIWQgghhBgESloIIYQQYhAoaSGEEEKIQaCkhRBCCCEGgZIWQgghhBgESloIIYQQYhAoaSGE9ChRUVF48803ueejR49u9U/vPw/ffvsteDxei7+rwuPxcODAgTa3uXLlSgwZMuSZ+lVeXg4ejwe5XP5M7RBiiChpIYS0KioqCjweDzwej/tl4NWrV6O+vv65H/vf//53m3/TpS2JBiHEcJl0dwcIIYYhKCgIGRkZqK2txdGjRzFnzhyYmprq/CKyVl1dHfh8fqccVyKRdEo7hBDDRysthJA2EQgEsLe3h7OzM2bNmoUxY8bg0KFDAP74Smft2rVwdHSEu7s7AKCyshLh4eHo1asXJBIJxo8fj/Lycq7NhoYGzJ8/H7169YKNjQ0WL16Mp38O7emvh2praxEfHw+pVAqBQABXV1ekp6ejvLwcAQEBAABra2vweDxERUUBANRqNdavX4/+/ftDKBTCx8cHe/fu1TnO0aNH4ebmBqFQiICAAJ1+tlV8fDzc3Nxgbm4OFxcXLFu2DE+ePNGrl5KSAqlUCnNzc4SHh6OmpkanPC0tDZ6enjAzM4OHhwe2bt3a7r4Q8iKipIUQ0iFCoRB1dXXc8xMnTqC4uBj5+fnIycnBkydPIJPJIBaLUVBQgDNnzkAkEiEoKIjbb9OmTcjMzMT27dvxn//8B9XV1di/f3+Lx3333Xexe/duJCUlQaFQICUlBSKRCFKpFPv27QMAFBcXQ6lUYvPmzQCA9evX4/PPP0dycjKuXLmCuLg4vPPOOzh16hQATXI1ceJEhIaGQi6XY8aMGfjwww/bPSZisRiZmZkoKirC5s2bkZqaisTERJ06paWl+Oqrr3D48GHk5ubi4sWLmD17Nle+c+dOLF++HGvXroVCocC6deuwbNky7Nixo939IeSF02W/J00IMViRkZFs/PjxjDHG1Go1y8/PZwKBgC1cuJArt7OzY7W1tdw+X3zxBXN3d2dqtZrbVltby4RCIcvLy2OMMebg4MA2btzIlT958oT17duXOxZjjPn7+7PY2FjGGGPFxcUMAMvPz2+ynydPnmQA2J07d7htjx8/Zubm5uzs2bM6dadPn86mTp3KGGPso48+Yl5eXjrl8fHxem09DQDbv39/s+WffPIJGzZsGPd8xYoVzNjYmP3888/ctmPHjjEjIyOmVCoZY4wNGDCA7dq1S6edhIQE5ufnxxhj7MaNGwwAu3jxYrPHJeRFRde0EELaJCcnByKRCE+ePIFarcbbb7+NlStXcuXe3t4617FcunQJpaWlEIvFOu08fvwY169fR01NDZRKJXx9fbkyExMTDB8+XO8rIi25XA5jY2P4+/u3ud+lpaV4+PAhAgMDdbbX1dVh6NChAACFQqHTDwDw8/Nr8zG0srOzkZSUhOvXr0OlUqG+vh6WlpY6dV566SU4OTnpHEetVqO4uBhisRjXr1/H9OnTER0dzdWpr6+HlZVVu/tDyIuGkhZCSJsEBARg27Zt4PP5cHR0hImJ7unDwsJC57lKpcKwYcOwc+dOvbZsbW071AehUNjufVQqFQDgyJEjOskCoLlOp7N89913iIiIwKpVqyCTyWBlZYWsrCxs2rSp3X1NTU3VS6KMjY07ra+EGCpKWgghbWJhYQFXV9c213/llVeQnZ2NPn366K02aDk4OOD8+fP4y1/+AkCzovDf//4Xr7zySpP1vb29oVarcerUKYwZM0avXLvS09DQwG3z8vKCQCBARUVFsys0np6e3EXFWufOnWs9yEbOnj0LZ2dnLFmyhNt28+ZNvXoVFRW4desWHB0dueMYGRnB3d0ddnZ2cHR0RFlZGSIiItp1fEL+DOhCXELIcxEREYHevXtj/PjxKCgowI0bN/Dtt99i7ty5+PnnnwEAsbGx2LBhAw4cOICrV69i9uzZLf6NlX79+iEyMhLTpk3DgQMHuDa/+uorAICzszN4PB5ycnJw+/ZtqFQqiMViLFy4EHFxcdixYweuX7+OH3/8Ef/85z+5i1tnzpyJkpISLFq0CMXFxdi1axcyMzPbFe/AgQNRUVGBrKwsXL9+HUlJSU1eVGxmZobIyEhcunQJBQUFmDt3LsLDw2Fvbw8AWLVqFdavX4+kpCRcu3YNhYWFyMjIwGeffdau/hDyIqKkhRDyXJibm+P06dN46aWXMHHiRHh6emL69Ol4/Pgxt/KyYMEC/O1vf0NkZCT8/PwgFosxYcKEFtvdtm0bwsLCMHv2bHh4eCA6OhoPHjwAADg5OWHVqlX48MMPYWdnhw8++AAAkJCQgGXLlmH9+vXw9PREUFAQjhw5gv79+wPQXGeyb98+HDhwAD4+PkhOTsa6devaFe+4ceMQFxeHDz74AEOGDMHZs2exbNkyvXqurq6YOHEiQkJCMHbsWAwePFjnluYZM2YgLS0NGRkZ8Pb2hr+/PzIzM7m+EvJnxmPNXfFGCCGEENKD0EoLIYQQQgwCJS2EEEIIMQiUtBBCCCHEIFDSQgghhBCDQEkLIYQQQgwCJS2EEEIIMQiUtBBCCCHEIFDSQgghhBCDQEkLIYQQQgwCJS2EEEIIMQiUtBBCCCHEIPw/P2PpmSNzhCUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix \n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show() \n",
    "    \n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"], tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], [] \n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\":labels, \"preds\": preds, \"losses\": losses}).T\n",
    "\n",
    "        yield df_tmp\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
